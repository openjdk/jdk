//
// Copyright (c) 2020, 2021, Oracle and/or its affiliates. All rights reserved.
// Copyright (c) 2020, 2021, Arm Limited. All rights reserved.
// DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
//
// This code is free software; you can redistribute it and/or modify it
// under the terms of the GNU General Public License version 2 only, as
// published by the Free Software Foundation.
//
// This code is distributed in the hope that it will be useful, but WITHOUT
// ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
// FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
// version 2 for more details (a copy is included in the LICENSE file that
// accompanied this code).
//
// You should have received a copy of the GNU General Public License version
// 2 along with this work; if not, write to the Free Software Foundation,
// Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
//
// Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
// or visit www.oracle.com if you need additional information or have any
// questions.
//
//

dnl Generate the warning
// This file is automatically generated by running "m4 aarch64_sve_ad.m4". Do not edit ----
dnl

// AArch64 SVE Architecture Description File

dnl
define(`TYPE2DATATYPE',
`ifelse($1, `B', `BYTE',
        $1, `S', `SHORT',
        $1, `I', `INT',
        $1, `L', `LONG',
        $1, `F', `FLOAT',
        $1, `D', `DOUBLE',
        `error($1)')')dnl
dnl
dnl OPERAND_VMEMORYA_IMMEDIATE_OFFSET($1,            $2,       $3       $4   )
dnl OPERAND_VMEMORYA_IMMEDIATE_OFFSET(imm_type_abbr, imm_type, imm_len, scale)
define(`OPERAND_VMEMORYA_IMMEDIATE_OFFSET', `
operand vmemA_imm$1Offset$3()
%{
  // (esize / msize) = $4
  predicate(Address::offset_ok_for_sve_immed(n->get_$2(), $3,
            Matcher::scalable_vector_reg_size(T_BYTE)ifelse($4, `1', `', ` / $4')));
  match(Con$1);

  op_cost(0);
  format %{ %}
  interface(CONST_INTER);
%}')dnl

// 4 bit signed offset -- for predicated load/store
OPERAND_VMEMORYA_IMMEDIATE_OFFSET(I, int,  4, 1)
OPERAND_VMEMORYA_IMMEDIATE_OFFSET(L, long, 4, 1)
dnl
dnl OPERAND_VMEMORYA_INDIRECT_OFFSET($1,            $2     )
dnl OPERAND_VMEMORYA_INDIRECT_OFFSET(imm_type_abbr, imm_len)
define(`OPERAND_VMEMORYA_INDIRECT_OFFSET', `
operand vmemA_indOff$1$2$3(iRegP reg, vmemA_imm$1Offset$2 off)
%{
  constraint(ALLOC_IN_RC(ptr_reg));
  match(AddP reg off);
  op_cost(0);
  format %{ "[$reg, $off]" %}
  interface(MEMORY_INTER) %{
    base($reg);
    `index'(0xffffffff);
    scale(0x0);
    disp($off);
  %}
%}')dnl
OPERAND_VMEMORYA_INDIRECT_OFFSET(I, 4)
OPERAND_VMEMORYA_INDIRECT_OFFSET(L, 4)

// The indOff of vmemA is valid only when the vector element (load to/store from)
// size equals to memory element (load from/store to) size.
opclass vmemA(indirect, vmemA_indOffI4, vmemA_indOffL4);

source_hpp %{
  bool op_sve_supported(int opcode, int vlen, BasicType bt);
%}

source %{

  static inline uint vector_length_in_bytes(const MachNode* n) {
    const TypeVect* vt = n->bottom_type()->is_vect();
    return vt->length_in_bytes();
  }

  static inline uint vector_length_in_bytes(const MachNode* use, MachOper* opnd) {
    uint def_idx = use->operand_index(opnd);
    Node* def = use->in(def_idx);
    const TypeVect* vt = def->bottom_type()->is_vect();
    return vt->length_in_bytes();
  }

  typedef void (C2_MacroAssembler::* sve_mem_insn_predicate)(FloatRegister Rt, Assembler::SIMD_RegVariant T,
                                                             PRegister Pg, const Address &adr);

  // Predicated load/store, with optional ptrue to all elements of given predicate register.
  static void loadStoreA_predicated(C2_MacroAssembler masm, bool is_store, FloatRegister reg,
                                    PRegister pg, BasicType mem_elem_bt, BasicType vector_elem_bt,
                                    int opcode, Register base, int index, int size, int disp) {
    sve_mem_insn_predicate insn;
    int mesize = type2aelembytes(mem_elem_bt);
    if (index == -1) {
      assert(size == 0, "unsupported address mode: scale size = %d", size);
      switch(mesize) {
      case 1:
        insn = is_store ? &C2_MacroAssembler::sve_st1b : &C2_MacroAssembler::sve_ld1b;
        break;
      case 2:
        insn = is_store ? &C2_MacroAssembler::sve_st1h : &C2_MacroAssembler::sve_ld1h;
        break;
      case 4:
        insn = is_store ? &C2_MacroAssembler::sve_st1w : &C2_MacroAssembler::sve_ld1w;
        break;
      case 8:
        insn = is_store ? &C2_MacroAssembler::sve_st1d : &C2_MacroAssembler::sve_ld1d;
        break;
      default:
        assert(false, "unsupported");
        ShouldNotReachHere();
      }
      int imm4 = disp / mesize / Matcher::scalable_vector_reg_size(vector_elem_bt);
      (masm.*insn)(reg, Assembler::elemType_to_regVariant(vector_elem_bt), pg, Address(base, imm4));
    } else {
      assert(false, "unimplemented");
      ShouldNotReachHere();
    }
  }

  bool op_sve_supported(int opcode, int vlen, BasicType bt) {
    int length_in_bytes = vlen * type2aelembytes(bt);
    switch (opcode) {
      case Op_MulAddVS2VI:
      // No multiply reduction instructions
      case Op_MulReductionVD:
      case Op_MulReductionVF:
      case Op_MulReductionVI:
      case Op_MulReductionVL:
      // Others
      case Op_ExtractC:
      case Op_ExtractUB:
        return false;
      // Vector API specific
      case Op_VectorLoadShuffle:
      case Op_VectorRearrange:
        if (vlen < 4 || length_in_bytes > MaxVectorSize) {
          return false;
        } else {
          return true;
        }
      case Op_LoadVector:
      case Op_StoreVector:
        return Matcher::vector_size_supported(bt, vlen);
      default:
        break;
    }
    // By default, we only support vector operations with no less than 8 bytes and 2 elements.
    return 8 <= length_in_bytes && length_in_bytes <= MaxVectorSize && vlen >= 2;
  }
%}

definitions %{
  int_def SVE_COST             (200, 200);
%}

dnl
dnl ELEMENT_SHORT_CHART($1, $2)
dnl ELEMENT_SHORT_CHART(etype, node)
define(`ELEMENT_SHORT_CHAR',`ifelse(`$1', `T_SHORT',
  `($2->bottom_type()->is_vect()->element_basic_type() == T_SHORT ||
            ($2->bottom_type()->is_vect()->element_basic_type() == T_CHAR))',
   `($2->bottom_type()->is_vect()->element_basic_type() == $1)')')dnl
dnl

// All SVE instructions

// vector load/store

// Unpredicated vector load/store
instruct loadV(vReg dst, vmemA mem) %{
  predicate(UseSVE > 0 && n->as_LoadVector()->memory_size() >= 16 &&
            n->as_LoadVector()->memory_size() == MaxVectorSize);
  match(Set dst (LoadVector mem));
  ins_cost(4 * SVE_COST);
  format %{ "sve_ldr $dst, $mem\t# vector (sve)" %}
  ins_encode %{
    FloatRegister dst_reg = as_FloatRegister($dst$$reg);
    BasicType bt = vector_element_basic_type(this);
    loadStoreA_predicated(C2_MacroAssembler(&cbuf), false, dst_reg, ptrue,
                          bt, bt, $mem->opcode(),
                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
  %}
  ins_pipe(pipe_slow);
%}

instruct storeV(vReg src, vmemA mem) %{
  predicate(UseSVE > 0 && n->as_StoreVector()->memory_size() >= 16 &&
            n->as_StoreVector()->memory_size() == MaxVectorSize);
  match(Set mem (StoreVector mem src));
  ins_cost(4 * SVE_COST);
  format %{ "sve_str $mem, $src\t# vector (sve)" %}
  ins_encode %{
    FloatRegister src_reg = as_FloatRegister($src$$reg);
    BasicType bt = vector_element_basic_type(this, $src);
    loadStoreA_predicated(C2_MacroAssembler(&cbuf), true, src_reg, ptrue,
                          bt, bt, $mem->opcode(),
                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
  %}
  ins_pipe(pipe_slow);
%}dnl

dnl
define(`VLoadStore', `
// ifelse(load, $3, Load, Store) Vector ($6 bits)
instruct $3V$4_vreg`'(vReg $7, vmem$4 mem)
%{
  predicate(UseSVE > 0 && `n->as_'ifelse(load, $3, Load, Store)Vector()->memory_size() == $4);
  match(Set ifelse(load, $3, dst (LoadVector mem), mem (StoreVector mem src)));
  ins_cost(4 * INSN_COST);
  format %{ "$1   ifelse(load, $3, `$dst,$mem', `$mem,$src')\t# vector ($6 bits)" %}
  ins_encode( `aarch64_enc_'ifelse(load, $3, ldr, str)v$2($7, mem) );
  ins_pipe(v$3`_reg_mem'ifelse(eval($4 * 8), 128, 128, 64));
%}')dnl
dnl        $1    $2 $3     $4  $5 $6   $7
VLoadStore(ldrh, H, load,  2,  D, 16,  dst)
VLoadStore(strh, H, store, 2,  D, 16,  src)
VLoadStore(ldrs, S, load,  4,  D, 32,  dst)
VLoadStore(strs, S, store, 4,  D, 32,  src)
VLoadStore(ldrd, D, load,  8,  D, 64,  dst)
VLoadStore(strd, D, store, 8,  D, 64,  src)
VLoadStore(ldrq, Q, load, 16,  X, 128, dst)
VLoadStore(strq, Q, store, 16, X, 128, src)

// Predicated vector load/store, based on the vector length of the node.
// Only load/store values in the range of the memory_size. This is needed
// when the memory_size is lower than the hardware supported max vector size.
// And this might happen for Vector API mask vector load/store.
instruct loadV_partial(vReg dst, vmemA mem, pRegGov pTmp, rFlagsReg cr) %{
  predicate(UseSVE > 0 && n->as_LoadVector()->memory_size() > 16 &&
            n->as_LoadVector()->memory_size() < MaxVectorSize);
  match(Set dst (LoadVector mem));
  effect(TEMP pTmp, KILL cr);
  ins_cost(6 * SVE_COST);
  format %{ "sve_whilelo_zr_imm $pTmp, vector_length\n\t"
            "sve_ldr $dst, $pTmp, $mem\t# load vector predicated" %}
  ins_encode %{
    BasicType bt = vector_element_basic_type(this);
    __ sve_whilelo_zr_imm(as_PRegister($pTmp$$reg), __ elemType_to_regVariant(bt), vector_length(this));
    FloatRegister dst_reg = as_FloatRegister($dst$$reg);
    loadStoreA_predicated(C2_MacroAssembler(&cbuf), false, dst_reg,
                          as_PRegister($pTmp$$reg), bt, bt, $mem->opcode(),
                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
  %}
  ins_pipe(pipe_slow);
%}

instruct storeV_partial(vReg src, vmemA mem, pRegGov pTmp, rFlagsReg cr) %{
  predicate(UseSVE > 0 && n->as_StoreVector()->memory_size() > 16 &&
            n->as_StoreVector()->memory_size() < MaxVectorSize);
  match(Set mem (StoreVector mem src));
  effect(TEMP pTmp, KILL cr);
  ins_cost(5 * SVE_COST);
  format %{ "sve_whilelo_zr_imm $pTmp, vector_length\n\t"
            "sve_str $src, $pTmp, $mem\t# store vector predicated" %}
  ins_encode %{
    BasicType bt = vector_element_basic_type(this, $src);
    __ sve_whilelo_zr_imm(as_PRegister($pTmp$$reg), __ elemType_to_regVariant(bt), vector_length(this, $src));
    FloatRegister src_reg = as_FloatRegister($src$$reg);
    loadStoreA_predicated(C2_MacroAssembler(&cbuf), true, src_reg,
                          as_PRegister($pTmp$$reg), bt, bt, $mem->opcode(),
                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
  %}
  ins_pipe(pipe_slow);
%}dnl


// vector reinterpret

instruct reinterpret(vReg dst) %{
  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() ==
                          n->in(1)->bottom_type()->is_vect()->length_in_bytes());  // src == dst
  match(Set dst (VectorReinterpret dst));
  ins_cost(0);
  format %{ "# reinterpret $dst\t# do nothing" %}
  ins_encode %{
    // empty
  %}
  ins_pipe(pipe_class_empty);
%}

instruct reinterpretResize(vReg dst, vReg src, pRegGov pTmp, rFlagsReg cr) %{
  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() !=
                          n->in(1)->bottom_type()->is_vect()->length_in_bytes());  // src != dst
  match(Set dst (VectorReinterpret src));
  effect(TEMP_DEF dst, TEMP pTmp, KILL cr);
  ins_cost(3 * SVE_COST);
  format %{ "reinterpretResize $dst, $src\t# vector (sve)" %}
  ins_encode %{
    uint length_in_bytes_src = vector_length_in_bytes(this, $src);
    uint length_in_bytes_dst = vector_length_in_bytes(this);
    uint length_in_bytes_resize = length_in_bytes_src < length_in_bytes_dst ?
                                  length_in_bytes_src : length_in_bytes_dst;
    assert(length_in_bytes_src <= MaxVectorSize && length_in_bytes_dst <= MaxVectorSize,
           "invalid vector length");
    __ sve_whilelo_zr_imm(as_PRegister($pTmp$$reg), __ B, length_in_bytes_resize);
    __ sve_dup(as_FloatRegister($dst$$reg), __ B, 0);
    __ sve_sel(as_FloatRegister($dst$$reg), __ B, as_PRegister($pTmp$$reg),
               as_FloatRegister($src$$reg), as_FloatRegister($dst$$reg));
  %}
  ins_pipe(pipe_slow);
%}
dnl
dnl UNARY_OP_TRUE_PREDICATE_ETYPE($1,        $2,      $3,           $4,   $5,          %6  )
dnl UNARY_OP_TRUE_PREDICATE_ETYPE(insn_name, op_name, element_type, size, min_vec_len, insn)
define(`UNARY_OP_TRUE_PREDICATE_ETYPE', `
instruct $1(vReg dst, vReg src) %{
  predicate(UseSVE > 0 &&
            n->bottom_type()->is_vect()->element_basic_type() == $3);
  match(Set dst ($2 src));
  ins_cost(SVE_COST);
  format %{ "$6 $dst, $src\t# vector (sve) ($4)" %}
  ins_encode %{
    __ $6(as_FloatRegister($dst$$reg), __ $4,
         ptrue, as_FloatRegister($src$$reg));
  %}
  ins_pipe(pipe_slow);
%}')dnl
dnl

// vector abs
UNARY_OP_TRUE_PREDICATE_ETYPE(vabsB, AbsVB, T_BYTE,   B, 16, sve_abs)
UNARY_OP_TRUE_PREDICATE_ETYPE(vabsS, AbsVS, T_SHORT,  H, 8,  sve_abs)
UNARY_OP_TRUE_PREDICATE_ETYPE(vabsI, AbsVI, T_INT,    S, 4,  sve_abs)
UNARY_OP_TRUE_PREDICATE_ETYPE(vabsL, AbsVL, T_LONG,   D, 2,  sve_abs)
UNARY_OP_TRUE_PREDICATE_ETYPE(vabsF, AbsVF, T_FLOAT,  S, 4,  sve_fabs)
UNARY_OP_TRUE_PREDICATE_ETYPE(vabsD, AbsVD, T_DOUBLE, D, 2,  sve_fabs)
dnl
dnl BINARY_OP_UNPREDICATED($1,        $2       $3,   $4           $5  )
dnl BINARY_OP_UNPREDICATED(insn_name, op_name, size, min_vec_len, insn)
define(`BINARY_OP_UNPREDICATED', `
instruct $1(vReg dst, vReg src1, vReg src2) %{
  predicate(UseSVE > 0);
  match(Set dst ($2 src1 src2));
  ins_cost(SVE_COST);
  format %{ "$5 $dst, $src1, $src2\t # vector (sve) ($3)" %}
  ins_encode %{
    __ $5(as_FloatRegister($dst$$reg), __ $3,
         as_FloatRegister($src1$$reg),
         as_FloatRegister($src2$$reg));
  %}
  ins_pipe(pipe_slow);
%}')dnl

// vector add
BINARY_OP_UNPREDICATED(vaddB, AddVB, B, 16, sve_add)
BINARY_OP_UNPREDICATED(vaddS, AddVS, H, 8,  sve_add)
BINARY_OP_UNPREDICATED(vaddI, AddVI, S, 4,  sve_add)
BINARY_OP_UNPREDICATED(vaddL, AddVL, D, 2,  sve_add)
BINARY_OP_UNPREDICATED(vaddF, AddVF, S, 4,  sve_fadd)
BINARY_OP_UNPREDICATED(vaddD, AddVD, D, 2,  sve_fadd)
dnl
dnl BINARY_OP_UNSIZED($1,        $2,      $3,          $4  )
dnl BINARY_OP_UNSIZED(insn_name, op_name, min_vec_len, insn)
define(`BINARY_OP_UNSIZED', `
instruct $1(vReg dst, vReg src1, vReg src2) %{
  predicate(UseSVE > 0);
  match(Set dst ($2 src1 src2));
  ins_cost(SVE_COST);
  format %{ "$4  $dst, $src1, $src2\t# vector (sve)" %}
  ins_encode %{
    __ $4(as_FloatRegister($dst$$reg),
         as_FloatRegister($src1$$reg),
         as_FloatRegister($src2$$reg));
  %}
  ins_pipe(pipe_slow);
%}')dnl

// vector and
BINARY_OP_UNSIZED(vand, AndV, 16, sve_and)

// vector or
BINARY_OP_UNSIZED(vor, OrV, 16, sve_orr)

// vector xor
BINARY_OP_UNSIZED(vxor, XorV, 16, sve_eor)

// vector not
dnl
define(`MATCH_RULE', `ifelse($1, I,
`match(Set dst (XorV src (ReplicateB m1)));
  match(Set dst (XorV src (ReplicateS m1)));
  match(Set dst (XorV src (ReplicateI m1)));',
`match(Set dst (XorV src (ReplicateL m1)));')')dnl
dnl
define(`VECTOR_NOT', `
instruct vnot$1`'(vReg dst, vReg src, imm$1_M1 m1) %{
  predicate(UseSVE > 0);
  MATCH_RULE($1)
  ins_cost(SVE_COST);
  format %{ "sve_not $dst, $src\t# vector (sve) $2" %}
  ins_encode %{
    __ sve_not(as_FloatRegister($dst$$reg), __ D,
               ptrue, as_FloatRegister($src$$reg));
  %}
  ins_pipe(pipe_slow);
%}')dnl
dnl        $1,$2
VECTOR_NOT(I, B/H/S)
VECTOR_NOT(L, D)
undefine(MATCH_RULE)

// vector and_not
dnl
define(`MATCH_RULE', `ifelse($1, I,
`match(Set dst (AndV src1 (XorV src2 (ReplicateB m1))));
  match(Set dst (AndV src1 (XorV src2 (ReplicateS m1))));
  match(Set dst (AndV src1 (XorV src2 (ReplicateI m1))));',
`match(Set dst (AndV src1 (XorV src2 (ReplicateL m1))));')')dnl
dnl
define(`VECTOR_AND_NOT', `
instruct vand_not$1`'(vReg dst, vReg src1, vReg src2, imm$1_M1 m1) %{
  predicate(UseSVE > 0);
  MATCH_RULE($1)
  ins_cost(SVE_COST);
  format %{ "sve_bic $dst, $src1, $src2\t# vector (sve) $2" %}
  ins_encode %{
    __ sve_bic(as_FloatRegister($dst$$reg),
               as_FloatRegister($src1$$reg),
               as_FloatRegister($src2$$reg));
  %}
  ins_pipe(pipe_slow);
%}')dnl
dnl            $1,$2
VECTOR_AND_NOT(I, B/H/S)
VECTOR_AND_NOT(L, D)
undefine(MATCH_RULE)
dnl
dnl VDIVF($1,          $2  , $3         )
dnl VDIVF(name_suffix, size, min_vec_len)
define(`VDIVF', `
instruct vdiv$1(vReg dst_src1, vReg src2) %{
  predicate(UseSVE > 0);
  match(Set dst_src1 (DivV$1 dst_src1 src2));
  ins_cost(SVE_COST);
  format %{ "sve_fdiv  $dst_src1, $dst_src1, $src2\t# vector (sve) ($2)" %}
  ins_encode %{
    __ sve_fdiv(as_FloatRegister($dst_src1$$reg), __ $2,
         ptrue, as_FloatRegister($src2$$reg));
  %}
  ins_pipe(pipe_slow);
%}')dnl

// vector float div
VDIVF(F, S, 4)
VDIVF(D, D, 2)

// vector min/max

instruct vmin(vReg dst_src1, vReg src2) %{
  predicate(UseSVE > 0);
  match(Set dst_src1 (MinV dst_src1 src2));
  ins_cost(SVE_COST);
  format %{ "sve_min $dst_src1, $dst_src1, $src2\t # vector (sve)" %}
  ins_encode %{
    BasicType bt = vector_element_basic_type(this);
    Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(bt);
    if (is_floating_point_type(bt)) {
      __ sve_fmin(as_FloatRegister($dst_src1$$reg), size,
                  ptrue, as_FloatRegister($src2$$reg));
    } else {
      assert(is_integral_type(bt), "Unsupported type");
      __ sve_smin(as_FloatRegister($dst_src1$$reg), size,
                  ptrue, as_FloatRegister($src2$$reg));
    }
  %}
  ins_pipe(pipe_slow);
%}

instruct vmax(vReg dst_src1, vReg src2) %{
  predicate(UseSVE > 0);
  match(Set dst_src1 (MaxV dst_src1 src2));
  ins_cost(SVE_COST);
  format %{ "sve_max $dst_src1, $dst_src1, $src2\t # vector (sve)" %}
  ins_encode %{
    BasicType bt = vector_element_basic_type(this);
    Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(bt);
    if (is_floating_point_type(bt)) {
      __ sve_fmax(as_FloatRegister($dst_src1$$reg), size,
                  ptrue, as_FloatRegister($src2$$reg));
    } else {
      assert(is_integral_type(bt), "Unsupported type");
      __ sve_smax(as_FloatRegister($dst_src1$$reg), size,
                  ptrue, as_FloatRegister($src2$$reg));
    }
  %}
  ins_pipe(pipe_slow);
%}

dnl
dnl VFMLA($1           $2    $3         )
dnl VFMLA(name_suffix, size, min_vec_len)
define(`VFMLA', `
// dst_src1 = dst_src1 + src2 * src3
instruct vfmla$1(vReg dst_src1, vReg src2, vReg src3) %{
  predicate(UseFMA && UseSVE > 0);
  match(Set dst_src1 (FmaV$1 dst_src1 (Binary src2 src3)));
  ins_cost(SVE_COST);
  format %{ "sve_fmla $dst_src1, $src2, $src3\t # vector (sve) ($2)" %}
  ins_encode %{
    __ sve_fmla(as_FloatRegister($dst_src1$$reg), __ $2,
         ptrue, as_FloatRegister($src2$$reg), as_FloatRegister($src3$$reg));
  %}
  ins_pipe(pipe_slow);
%}')dnl
dnl
// vector fmla
VFMLA(F, S, 4)
VFMLA(D, D, 2)

dnl
dnl VFMLS($1           $2    $3         )
dnl VFMLS(name_suffix, size, min_vec_len)
define(`VFMLS', `
// dst_src1 = dst_src1 + -src2 * src3
// dst_src1 = dst_src1 + src2 * -src3
instruct vfmls$1(vReg dst_src1, vReg src2, vReg src3) %{
  predicate(UseFMA && UseSVE > 0);
  match(Set dst_src1 (FmaV$1 dst_src1 (Binary (NegV$1 src2) src3)));
  match(Set dst_src1 (FmaV$1 dst_src1 (Binary src2 (NegV$1 src3))));
  ins_cost(SVE_COST);
  format %{ "sve_fmls $dst_src1, $src2, $src3\t # vector (sve) ($2)" %}
  ins_encode %{
    __ sve_fmls(as_FloatRegister($dst_src1$$reg), __ $2,
         ptrue, as_FloatRegister($src2$$reg), as_FloatRegister($src3$$reg));
  %}
  ins_pipe(pipe_slow);
%}')dnl
dnl
// vector fmls
VFMLS(F, S, 4)
VFMLS(D, D, 2)

dnl
dnl VFNMLA($1           $2    $3         )
dnl VFNMLA(name_suffix, size, min_vec_len)
define(`VFNMLA', `
// dst_src1 = -dst_src1 + -src2 * src3
// dst_src1 = -dst_src1 + src2 * -src3
instruct vfnmla$1(vReg dst_src1, vReg src2, vReg src3) %{
  predicate(UseFMA && UseSVE > 0);
  match(Set dst_src1 (FmaV$1 (NegV$1 dst_src1) (Binary (NegV$1 src2) src3)));
  match(Set dst_src1 (FmaV$1 (NegV$1 dst_src1) (Binary src2 (NegV$1 src3))));
  ins_cost(SVE_COST);
  format %{ "sve_fnmla $dst_src1, $src2, $src3\t # vector (sve) ($2)" %}
  ins_encode %{
    __ sve_fnmla(as_FloatRegister($dst_src1$$reg), __ $2,
         ptrue, as_FloatRegister($src2$$reg), as_FloatRegister($src3$$reg));
  %}
  ins_pipe(pipe_slow);
%}')dnl
dnl
// vector fnmla
VFNMLA(F, S, 4)
VFNMLA(D, D, 2)

dnl
dnl VFNMLS($1           $2    $3         )
dnl VFNMLS(name_suffix, size, min_vec_len)
define(`VFNMLS', `
// dst_src1 = -dst_src1 + src2 * src3
instruct vfnmls$1(vReg dst_src1, vReg src2, vReg src3) %{
  predicate(UseFMA && UseSVE > 0);
  match(Set dst_src1 (FmaV$1 (NegV$1 dst_src1) (Binary src2 src3)));
  ins_cost(SVE_COST);
  format %{ "sve_fnmls $dst_src1, $src2, $src3\t # vector (sve) ($2)" %}
  ins_encode %{
    __ sve_fnmls(as_FloatRegister($dst_src1$$reg), __ $2,
         ptrue, as_FloatRegister($src2$$reg), as_FloatRegister($src3$$reg));
  %}
  ins_pipe(pipe_slow);
%}')dnl
dnl
// vector fnmls
VFNMLS(F, S, 4)
VFNMLS(D, D, 2)

dnl
dnl VMLA($1           $2    $3         )
dnl VMLA(name_suffix, size, min_vec_len)
define(`VMLA', `
// dst_src1 = dst_src1 + src2 * src3
instruct vmla$1(vReg dst_src1, vReg src2, vReg src3)
%{
  predicate(UseSVE > 0);
  match(Set dst_src1 (AddV$1 dst_src1 (MulV$1 src2 src3)));
  ins_cost(SVE_COST);
  format %{ "sve_mla $dst_src1, src2, src3\t # vector (sve) ($2)" %}
  ins_encode %{
    __ sve_mla(as_FloatRegister($dst_src1$$reg), __ $2,
      ptrue, as_FloatRegister($src2$$reg), as_FloatRegister($src3$$reg));
  %}
  ins_pipe(pipe_slow);
%}')dnl
dnl
// vector mla
VMLA(B, B, 16)
VMLA(S, H, 8)
VMLA(I, S, 4)
VMLA(L, D, 2)

dnl
dnl VMLS($1           $2    $3         )
dnl VMLS(name_suffix, size, min_vec_len)
define(`VMLS', `
// dst_src1 = dst_src1 - src2 * src3
instruct vmls$1(vReg dst_src1, vReg src2, vReg src3)
%{
  predicate(UseSVE > 0);
  match(Set dst_src1 (SubV$1 dst_src1 (MulV$1 src2 src3)));
  ins_cost(SVE_COST);
  format %{ "sve_mls $dst_src1, src2, src3\t # vector (sve) ($2)" %}
  ins_encode %{
    __ sve_mls(as_FloatRegister($dst_src1$$reg), __ $2,
      ptrue, as_FloatRegister($src2$$reg), as_FloatRegister($src3$$reg));
  %}
  ins_pipe(pipe_slow);
%}')dnl
dnl
// vector mls
VMLS(B, B, 16)
VMLS(S, H, 8)
VMLS(I, S, 4)
VMLS(L, D, 2)

dnl
dnl BINARY_OP_TRUE_PREDICATE($1,        $2,      $3,   $4,          $5  )
dnl BINARY_OP_TRUE_PREDICATE(insn_name, op_name, size, min_vec_len, insn)
define(`BINARY_OP_TRUE_PREDICATE', `
instruct $1(vReg dst_src1, vReg src2) %{
  predicate(UseSVE > 0);
  match(Set dst_src1 ($2 dst_src1 src2));
  ins_cost(SVE_COST);
  format %{ "$5 $dst_src1, $dst_src1, $src2\t # vector (sve) ($3)" %}
  ins_encode %{
    __ $5(as_FloatRegister($dst_src1$$reg), __ $3,
         ptrue, as_FloatRegister($src2$$reg));
  %}
  ins_pipe(pipe_slow);
%}')dnl

// vector mul
BINARY_OP_TRUE_PREDICATE(vmulB, MulVB, B, 16, sve_mul)
BINARY_OP_TRUE_PREDICATE(vmulS, MulVS, H, 8,  sve_mul)
BINARY_OP_TRUE_PREDICATE(vmulI, MulVI, S, 4,  sve_mul)
BINARY_OP_TRUE_PREDICATE(vmulL, MulVL, D, 2,  sve_mul)
BINARY_OP_UNPREDICATED(vmulF, MulVF, S, 4, sve_fmul)
BINARY_OP_UNPREDICATED(vmulD, MulVD, D, 2, sve_fmul)

dnl
dnl UNARY_OP_TRUE_PREDICATE($1,        $2,      $3,   $4,            $5  )
dnl UNARY_OP_TRUE_PREDICATE(insn_name, op_name, size, min_vec_bytes, insn)
define(`UNARY_OP_TRUE_PREDICATE', `
instruct $1(vReg dst, vReg src) %{
  predicate(UseSVE > 0);
  match(Set dst ($2 src));
  ins_cost(SVE_COST);
  format %{ "$5 $dst, $src\t# vector (sve) ($3)" %}
  ins_encode %{
    __ $5(as_FloatRegister($dst$$reg), __ $3,
         ptrue, as_FloatRegister($src$$reg));
  %}
  ins_pipe(pipe_slow);
%}')dnl
dnl
// vector fneg
UNARY_OP_TRUE_PREDICATE(vnegF, NegVF, S, 16, sve_fneg)
UNARY_OP_TRUE_PREDICATE(vnegD, NegVD, D, 16, sve_fneg)

// popcount vector

instruct vpopcountI(vReg dst, vReg src) %{
  predicate(UseSVE > 0);
  match(Set dst (PopCountVI src));
  format %{ "sve_cnt $dst, $src\t# vector (sve) (S)\n\t" %}
  ins_encode %{
     __ sve_cnt(as_FloatRegister($dst$$reg), __ S, ptrue, as_FloatRegister($src$$reg));
  %}
  ins_pipe(pipe_slow);
%}

// vector mask compare

instruct vmaskcmp(vReg dst, vReg src1, vReg src2, immI cond, pRegGov pTmp, rFlagsReg cr) %{
  predicate(UseSVE > 0);
  match(Set dst (VectorMaskCmp (Binary src1 src2) cond));
  effect(TEMP pTmp, KILL cr);
  ins_cost(2 * SVE_COST);
  format %{ "sve_cmp $pTmp, $src1, $src2\n\t"
            "sve_cpy $dst, $pTmp, -1\t# vector mask cmp (sve)" %}
  ins_encode %{
    BasicType bt = vector_element_basic_type(this);
    __ sve_compare(as_PRegister($pTmp$$reg), bt, ptrue, as_FloatRegister($src1$$reg),
                   as_FloatRegister($src2$$reg), (int)$cond$$constant);
    __ sve_cpy(as_FloatRegister($dst$$reg), __ elemType_to_regVariant(bt),
               as_PRegister($pTmp$$reg), -1, false);
  %}
  ins_pipe(pipe_slow);
%}

// vector blend

instruct vblend(vReg dst, vReg src1, vReg src2, vReg src3, pRegGov pTmp, rFlagsReg cr) %{
  predicate(UseSVE > 0);
  match(Set dst (VectorBlend (Binary src1 src2) src3));
  effect(TEMP pTmp, KILL cr);
  ins_cost(2 * SVE_COST);
  format %{ "sve_cmpeq $pTmp, $src3, -1\n\t"
            "sve_sel $dst, $pTmp, $src2, $src1\t# vector blend (sve)" %}
  ins_encode %{
    Assembler::SIMD_RegVariant size =
      __ elemType_to_regVariant(vector_element_basic_type(this));
    __ sve_cmpeq(as_PRegister($pTmp$$reg), size, ptrue,
                 as_FloatRegister($src3$$reg), -1);
    __ sve_sel(as_FloatRegister($dst$$reg), size, as_PRegister($pTmp$$reg),
               as_FloatRegister($src2$$reg), as_FloatRegister($src1$$reg));
  %}
  ins_pipe(pipe_slow);
%}

// vector blend with compare

instruct vblend_maskcmp(vReg dst, vReg src1, vReg src2, vReg src3,
                        vReg src4, pRegGov pTmp, immI cond, rFlagsReg cr) %{
  predicate(UseSVE > 0);
  match(Set dst (VectorBlend (Binary src1 src2) (VectorMaskCmp (Binary src3 src4) cond)));
  effect(TEMP pTmp, KILL cr);
  ins_cost(2 * SVE_COST);
  format %{ "sve_cmp $pTmp, $src3, $src4\t# vector cmp (sve)\n\t"
            "sve_sel $dst, $pTmp, $src2, $src1\t# vector blend (sve)" %}
  ins_encode %{
    BasicType bt = vector_element_basic_type(this);
    __ sve_compare(as_PRegister($pTmp$$reg), bt, ptrue, as_FloatRegister($src3$$reg),
                   as_FloatRegister($src4$$reg), (int)$cond$$constant);
    __ sve_sel(as_FloatRegister($dst$$reg), __ elemType_to_regVariant(bt),
               as_PRegister($pTmp$$reg), as_FloatRegister($src2$$reg),
               as_FloatRegister($src1$$reg));
  %}
  ins_pipe(pipe_slow);
%}

// vector load mask

instruct vloadmaskB(vReg dst, vReg src) %{
  predicate(UseSVE > 0 &&
            n->bottom_type()->is_vect()->element_basic_type() == T_BYTE);
  match(Set dst (VectorLoadMask src));
  ins_cost(SVE_COST);
  format %{ "sve_neg $dst, $src\t# vector load mask (B)" %}
  ins_encode %{
    __ sve_neg(as_FloatRegister($dst$$reg), __ B, ptrue, as_FloatRegister($src$$reg));
  %}
  ins_pipe(pipe_slow);
%}

instruct vloadmaskS(vReg dst, vReg src) %{
  predicate(UseSVE > 0 &&
            n->bottom_type()->is_vect()->element_basic_type() == T_SHORT);
  match(Set dst (VectorLoadMask src));
  ins_cost(2 * SVE_COST);
  format %{ "sve_uunpklo $dst, H, $src\n\t"
            "sve_neg $dst, $dst\t# vector load mask (B to H)" %}
  ins_encode %{
    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($src$$reg));
    __ sve_neg(as_FloatRegister($dst$$reg), __ H, ptrue, as_FloatRegister($dst$$reg));
  %}
  ins_pipe(pipe_slow);
%}

instruct vloadmaskI(vReg dst, vReg src) %{
  predicate(UseSVE > 0 &&
            (n->bottom_type()->is_vect()->element_basic_type() == T_INT ||
             n->bottom_type()->is_vect()->element_basic_type() == T_FLOAT));
  match(Set dst (VectorLoadMask src));
  ins_cost(3 * SVE_COST);
  format %{ "sve_uunpklo $dst, H, $src\n\t"
            "sve_uunpklo $dst, S, $dst\n\t"
            "sve_neg $dst, $dst\t# vector load mask (B to S)" %}
  ins_encode %{
    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($src$$reg));
    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($dst$$reg));
    __ sve_neg(as_FloatRegister($dst$$reg), __ S, ptrue, as_FloatRegister($dst$$reg));
  %}
  ins_pipe(pipe_slow);
%}

instruct vloadmaskL(vReg dst, vReg src) %{
  predicate(UseSVE > 0 &&
            (n->bottom_type()->is_vect()->element_basic_type() == T_LONG ||
             n->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE));
  match(Set dst (VectorLoadMask src));
  ins_cost(4 * SVE_COST);
  format %{ "sve_uunpklo $dst, H, $src\n\t"
            "sve_uunpklo $dst, S, $dst\n\t"
            "sve_uunpklo $dst, D, $dst\n\t"
            "sve_neg $dst, $dst\t# vector load mask (B to D)" %}
  ins_encode %{
    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($src$$reg));
    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($dst$$reg));
    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ D, as_FloatRegister($dst$$reg));
    __ sve_neg(as_FloatRegister($dst$$reg), __ D, ptrue, as_FloatRegister($dst$$reg));
  %}
  ins_pipe(pipe_slow);
%}

// vector store mask

instruct vstoremaskB(vReg dst, vReg src, immI_1 size) %{
  predicate(UseSVE > 0);
  match(Set dst (VectorStoreMask src size));
  ins_cost(SVE_COST);
  format %{ "sve_neg $dst, $src\t# vector store mask (B)" %}
  ins_encode %{
    __ sve_neg(as_FloatRegister($dst$$reg), __ B, ptrue,
               as_FloatRegister($src$$reg));
  %}
  ins_pipe(pipe_slow);
%}

instruct vstoremaskS(vReg dst, vReg src, vReg tmp, immI_2 size) %{
  predicate(UseSVE > 0);
  match(Set dst (VectorStoreMask src size));
  effect(TEMP_DEF dst, TEMP tmp);
  ins_cost(3 * SVE_COST);
  format %{ "sve_dup $tmp, H, 0\n\t"
            "sve_uzp1 $dst, B, $src, $tmp\n\t"
            "sve_neg $dst, B, $dst\t# vector store mask (sve) (H to B)" %}
  ins_encode %{
    __ sve_dup(as_FloatRegister($tmp$$reg), __ H, 0);
    __ sve_uzp1(as_FloatRegister($dst$$reg), __ B,
                as_FloatRegister($src$$reg), as_FloatRegister($tmp$$reg));
    __ sve_neg(as_FloatRegister($dst$$reg), __ B, ptrue,
               as_FloatRegister($dst$$reg));

  %}
  ins_pipe(pipe_slow);
%}

instruct vstoremaskI(vReg dst, vReg src, vReg tmp, immI_4 size) %{
  predicate(UseSVE > 0);
  match(Set dst (VectorStoreMask src size));
  effect(TEMP_DEF dst, TEMP tmp);
  ins_cost(4 * SVE_COST);
  format %{ "sve_dup $tmp, S, 0\n\t"
            "sve_uzp1 $dst, H, $src, $tmp\n\t"
            "sve_uzp1 $dst, B, $dst, $tmp\n\t"
            "sve_neg $dst, B, $dst\t# vector store mask (sve) (S to B)" %}
  ins_encode %{
    __ sve_dup(as_FloatRegister($tmp$$reg), __ S, 0);
    __ sve_uzp1(as_FloatRegister($dst$$reg), __ H,
                as_FloatRegister($src$$reg), as_FloatRegister($tmp$$reg));
    __ sve_uzp1(as_FloatRegister($dst$$reg), __ B,
                as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
    __ sve_neg(as_FloatRegister($dst$$reg), __ B, ptrue,
               as_FloatRegister($dst$$reg));
  %}
  ins_pipe(pipe_slow);
%}

instruct vstoremaskL(vReg dst, vReg src, vReg tmp, immI_8 size) %{
  predicate(UseSVE > 0);
  match(Set dst (VectorStoreMask src size));
  effect(TEMP_DEF dst, TEMP tmp);
  ins_cost(5 * SVE_COST);
  format %{ "sve_dup $tmp, D, 0\n\t"
            "sve_uzp1 $dst, S, $src, $tmp\n\t"
            "sve_uzp1 $dst, H, $dst, $tmp\n\t"
            "sve_uzp1 $dst, B, $dst, $tmp\n\t"
            "sve_neg $dst, B, $dst\t# vector store mask (sve) (D to B)" %}
  ins_encode %{
    __ sve_dup(as_FloatRegister($tmp$$reg), __ D, 0);
    __ sve_uzp1(as_FloatRegister($dst$$reg), __ S,
                as_FloatRegister($src$$reg), as_FloatRegister($tmp$$reg));
    __ sve_uzp1(as_FloatRegister($dst$$reg), __ H,
                as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
    __ sve_uzp1(as_FloatRegister($dst$$reg), __ B,
                as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
    __ sve_neg(as_FloatRegister($dst$$reg), __ B, ptrue,
               as_FloatRegister($dst$$reg));
  %}
  ins_pipe(pipe_slow);
%}
dnl
dnl
dnl VLOADMASK_LOADV($1,    $2  )
dnl VLOADMASK_LOADV(esize, cond)
define(`VLOADMASK_LOADV', `
instruct vloadmask_loadV_$1(vReg dst, ifelse($1, `byte', vmemA, indirect) mem) %{
  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() == MaxVectorSize &&
            type2aelembytes(n->bottom_type()->is_vect()->element_basic_type()) $2);
  match(Set dst (VectorLoadMask (LoadVector mem)));
  ins_cost(5 * SVE_COST);
  format %{ "sve_ld1b $dst, $mem\n\t"
            "sve_neg $dst, $dst\t# load vector mask (sve)" %}
  ins_encode %{
    FloatRegister dst_reg = as_FloatRegister($dst$$reg);
    BasicType to_vect_bt = vector_element_basic_type(this);
    Assembler::SIMD_RegVariant to_vect_variant = __ elemType_to_regVariant(to_vect_bt);
    loadStoreA_predicated(C2_MacroAssembler(&cbuf), false, dst_reg, ptrue,
                          T_BOOLEAN, to_vect_bt, $mem->opcode(),
                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
    __ sve_neg(dst_reg, to_vect_variant, ptrue, dst_reg);
  %}
  ins_pipe(pipe_slow);
%}')dnl
dnl
define(`ARGLIST',
`ifelse($1, `byte', vmemA, indirect) mem, vReg src, vReg tmp, ifelse($1, `byte', immI_1, immI_gt_1) esize')
dnl
dnl STOREV_VSTOREMASK($1,  )
dnl STOREV_VSTOREMASK(esize)
define(`STOREV_VSTOREMASK', `
instruct storeV_vstoremask_$1(ARGLIST($1)) %{
  predicate(UseSVE > 0 && n->as_StoreVector()->memory_size() *
                          n->as_StoreVector()->in(MemNode::ValueIn)->in(2)->get_int() == MaxVectorSize);
  match(Set mem (StoreVector mem (VectorStoreMask src esize)));
  effect(TEMP tmp);
  ins_cost(5 * SVE_COST);
  format %{ "sve_neg $tmp, $src\n\t"
            "sve_st1b $tmp, $mem\t# store vector mask (sve)" %}
  ins_encode %{
    BasicType from_vect_bt = vector_element_basic_type(this, $src);
    assert(type2aelembytes(from_vect_bt) == (int)$esize$$constant, "unsupported type.");
    Assembler::SIMD_RegVariant from_vect_variant = __ elemBytes_to_regVariant($esize$$constant);
    __ sve_neg(as_FloatRegister($tmp$$reg), from_vect_variant, ptrue,
               as_FloatRegister($src$$reg));
    loadStoreA_predicated(C2_MacroAssembler(&cbuf), true, as_FloatRegister($tmp$$reg),
                          ptrue, T_BOOLEAN, from_vect_bt, $mem->opcode(),
                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
  %}
  ins_pipe(pipe_slow);
%}')dnl
undefine(ARGLIST)dnl
dnl
// load/store mask vector
VLOADMASK_LOADV(byte, == 1)
VLOADMASK_LOADV(non_byte, > 1)
STOREV_VSTOREMASK(byte)
STOREV_VSTOREMASK(non_byte)

// vector add reduction

instruct reduce_addI(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp) %{
  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);
  match(Set dst (AddReductionVI src1 src2));
  effect(TEMP_DEF dst, TEMP vtmp);
  ins_cost(SVE_COST);
  format %{ "sve_reduce_addI $dst, $src1, $src2\t# addB/S/I reduction (sve) (may extend)" %}
  ins_encode %{
    BasicType bt = vector_element_basic_type(this, $src2);
    Assembler::SIMD_RegVariant variant = __ elemType_to_regVariant(bt);
    __ sve_uaddv(as_FloatRegister($vtmp$$reg), variant, ptrue, as_FloatRegister($src2$$reg));
    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), variant, 0);
    __ addw($dst$$Register, $dst$$Register, $src1$$Register);
    if (bt == T_BYTE) {
      __ sxtb($dst$$Register, $dst$$Register);
    } else if (bt == T_SHORT) {
      __ sxth($dst$$Register, $dst$$Register);
    } else {
      assert(bt == T_INT, "unsupported type");
    }
  %}
  ins_pipe(pipe_slow);
%}

instruct reduce_addI_partial(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp,
                             pRegGov ptmp, rFlagsReg cr) %{
  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);
  match(Set dst (AddReductionVI src1 src2));
  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);
  ins_cost(SVE_COST);
  format %{ "sve_reduce_addI $dst, $src1, $src2\t# addI reduction partial (sve) (may extend)" %}
  ins_encode %{
    BasicType bt = vector_element_basic_type(this, $src2);
    Assembler::SIMD_RegVariant variant = __ elemType_to_regVariant(bt);
    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), variant, vector_length(this, $src2));
    __ sve_uaddv(as_FloatRegister($vtmp$$reg), variant,
                 as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));
    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), variant, 0);
    __ addw($dst$$Register, $dst$$Register, $src1$$Register);
    if (bt == T_BYTE) {
      __ sxtb($dst$$Register, $dst$$Register);
    } else if (bt == T_SHORT) {
      __ sxth($dst$$Register, $dst$$Register);
    } else {
      assert(bt == T_INT, "unsupported type");
    }
  %}
  ins_pipe(pipe_slow);
%}

instruct reduce_addL(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp) %{
  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);
  match(Set dst (AddReductionVL src1 src2));
  effect(TEMP_DEF dst, TEMP vtmp);
  ins_cost(SVE_COST);
  format %{ "sve_reduce_addL $dst, $src1, $src2\t# addL reduction (sve)" %}
  ins_encode %{
    __ sve_uaddv(as_FloatRegister($vtmp$$reg), __ D, ptrue, as_FloatRegister($src2$$reg));
    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), __ D, 0);
    __ add($dst$$Register, $dst$$Register, $src1$$Register);
  %}
  ins_pipe(pipe_slow);
%}

instruct reduce_addL_partial(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp,
                             pRegGov ptmp, rFlagsReg cr) %{
  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);
  match(Set dst (AddReductionVL src1 src2));
  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);
  ins_cost(SVE_COST);
  format %{ "sve_reduce_addL $dst, $src1, $src2\t# addL reduction partial (sve)" %}
  ins_encode %{
    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), __ D, vector_length(this, $src2));
    __ sve_uaddv(as_FloatRegister($vtmp$$reg), __ D,
                 as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));
    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), __ D, 0);
    __ add($dst$$Register, $dst$$Register, $src1$$Register);
  %}
  ins_pipe(pipe_slow);
%}

dnl
dnl REDUCE_ADDF($1,        $2,      $3,      $4  )
dnl REDUCE_ADDF(insn_name, op_name, reg_dst, size)
define(`REDUCE_ADDF', `
instruct $1($3 src1_dst, vReg src2) %{
  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);
  match(Set src1_dst (AddReductionV$2 src1_dst src2));
  ins_cost(SVE_COST);
  format %{ "sve_fadda $src1_dst, $src1_dst, $src2\t# vector (sve) ($4)" %}
  ins_encode %{
    __ sve_fadda(as_FloatRegister($src1_dst$$reg), __ $4,
         ptrue, as_FloatRegister($src2$$reg));
  %}
  ins_pipe(pipe_slow);
%}')dnl
dnl
dnl
dnl REDUCE_ADDF_PARTIAL($1,        $2,     $3,      $4  )
dnl REDUCE_ADDF_PARTIAL(insn_name, suffix, reg_dst, size)
define(`REDUCE_ADDF_PARTIAL', `
instruct $1($3 src1_dst, vReg src2, pRegGov ptmp, rFlagsReg cr) %{
  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);
  match(Set src1_dst (AddReductionV$2 src1_dst src2));
  ins_cost(SVE_COST);
  effect(TEMP ptmp, KILL cr);
  format %{ "sve_reduce_add$2 $src1_dst, $src1_dst, $src2\t# add$2 reduction partial (sve) ($4)" %}
  ins_encode %{
    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), __ $4, vector_length(this, $src2));
    __ sve_fadda(as_FloatRegister($src1_dst$$reg), __ $4,
                 as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));
  %}
  ins_pipe(pipe_slow);
%}')dnl
dnl
REDUCE_ADDF(reduce_addF, F, vRegF, S)
REDUCE_ADDF_PARTIAL(reduce_addF_partial, F, vRegF, S)
REDUCE_ADDF(reduce_addD, D, vRegD, D)
REDUCE_ADDF_PARTIAL(reduce_addD_partial, D, vRegD, D)

// vector and reduction

instruct reduce_andI(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp) %{
  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG &&
            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);
  match(Set dst (AndReductionV src1 src2));
  effect(TEMP_DEF dst, TEMP vtmp);
  ins_cost(SVE_COST);
  format %{ "sve_reduce_andI $dst, $src1, $src2\t# andB/S/I reduction (sve) (may extend)" %}
  ins_encode %{
    BasicType bt = vector_element_basic_type(this, $src2);
    Assembler::SIMD_RegVariant variant = __ elemType_to_regVariant(bt);
    __ sve_andv(as_FloatRegister($vtmp$$reg), variant, ptrue, as_FloatRegister($src2$$reg));
    __ smov($dst$$Register, as_FloatRegister($vtmp$$reg), variant, 0);
    __ andw($dst$$Register, $dst$$Register, $src1$$Register);
    if (bt == T_BYTE) {
      __ sxtb($dst$$Register, $dst$$Register);
    } else if (bt == T_SHORT) {
      __ sxth($dst$$Register, $dst$$Register);
    } else {
      assert(bt == T_INT, "unsupported type");
    }
  %}
  ins_pipe(pipe_slow);
%}

instruct reduce_andI_partial(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp,
                             pRegGov ptmp, rFlagsReg cr) %{
  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG &&
            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);
  match(Set dst (AndReductionV src1 src2));
  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);
  ins_cost(SVE_COST);
  format %{ "sve_reduce_andI $dst, $src1, $src2\t# andI reduction partial (sve) (may extend)" %}
  ins_encode %{
    BasicType bt = vector_element_basic_type(this, $src2);
    Assembler::SIMD_RegVariant variant = __ elemType_to_regVariant(bt);
    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), variant, vector_length(this, $src2));
    __ sve_andv(as_FloatRegister($vtmp$$reg), variant,
                as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));
    __ smov($dst$$Register, as_FloatRegister($vtmp$$reg), variant, 0);
    __ andw($dst$$Register, $dst$$Register, $src1$$Register);
    if (bt == T_BYTE) {
      __ sxtb($dst$$Register, $dst$$Register);
    } else if (bt == T_SHORT) {
      __ sxth($dst$$Register, $dst$$Register);
    } else {
      assert(bt == T_INT, "unsupported type");
    }
  %}
  ins_pipe(pipe_slow);
%}

instruct reduce_andL(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp) %{
  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG &&
            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);
  match(Set dst (AndReductionV src1 src2));
  effect(TEMP_DEF dst, TEMP vtmp);
  ins_cost(SVE_COST);
  format %{ "sve_reduce_andL $dst, $src1, $src2\t# andL reduction (sve)" %}
  ins_encode %{
    __ sve_andv(as_FloatRegister($vtmp$$reg), __ D, ptrue, as_FloatRegister($src2$$reg));
    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), __ D, 0);
    __ andr($dst$$Register, $dst$$Register, $src1$$Register);
  %}
  ins_pipe(pipe_slow);
%}

instruct reduce_andL_partial(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp,
                             pRegGov ptmp, rFlagsReg cr) %{
  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG &&
            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);
  match(Set dst (AndReductionV src1 src2));
  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);
  ins_cost(SVE_COST);
  format %{ "sve_reduce_andL $dst, $src1, $src2\t# andL reduction partial (sve)" %}
  ins_encode %{
    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), __ D, vector_length(this, $src2));
    __ sve_andv(as_FloatRegister($vtmp$$reg), __ D,
                as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));
    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), __ D, 0);
    __ andr($dst$$Register, $dst$$Register, $src1$$Register);
  %}
  ins_pipe(pipe_slow);
%}

// vector or reduction

instruct reduce_orI(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp) %{
  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG &&
            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);
  match(Set dst (OrReductionV src1 src2));
  effect(TEMP_DEF dst, TEMP vtmp);
  ins_cost(SVE_COST);
  format %{ "sve_reduce_orI $dst, $src1, $src2\t# orB/S/I reduction (sve) (may extend)" %}
  ins_encode %{
    BasicType bt = vector_element_basic_type(this, $src2);
    Assembler::SIMD_RegVariant variant = __ elemType_to_regVariant(bt);
    __ sve_orv(as_FloatRegister($vtmp$$reg), variant, ptrue, as_FloatRegister($src2$$reg));
    __ smov($dst$$Register, as_FloatRegister($vtmp$$reg), variant, 0);
    __ orrw($dst$$Register, $dst$$Register, $src1$$Register);
    if (bt == T_BYTE) {
      __ sxtb($dst$$Register, $dst$$Register);
    } else if (bt == T_SHORT) {
      __ sxth($dst$$Register, $dst$$Register);
    } else {
      assert(bt == T_INT, "unsupported type");
    }
  %}
  ins_pipe(pipe_slow);
%}

instruct reduce_orI_partial(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp,
                             pRegGov ptmp, rFlagsReg cr) %{
  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG &&
            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);
  match(Set dst (OrReductionV src1 src2));
  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);
  ins_cost(SVE_COST);
  format %{ "sve_reduce_orI $dst, $src1, $src2\t# orI reduction partial (sve) (may extend)" %}
  ins_encode %{
    BasicType bt = vector_element_basic_type(this, $src2);
    Assembler::SIMD_RegVariant variant = __ elemType_to_regVariant(bt);
    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), variant, vector_length(this, $src2));
    __ sve_orv(as_FloatRegister($vtmp$$reg), variant,
               as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));
    __ smov($dst$$Register, as_FloatRegister($vtmp$$reg), variant, 0);
    __ orrw($dst$$Register, $dst$$Register, $src1$$Register);
    if (bt == T_BYTE) {
      __ sxtb($dst$$Register, $dst$$Register);
    } else if (bt == T_SHORT) {
      __ sxth($dst$$Register, $dst$$Register);
    } else {
      assert(bt == T_INT, "unsupported type");
    }
  %}
  ins_pipe(pipe_slow);
%}

instruct reduce_orL(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp) %{
  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG &&
            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);
  match(Set dst (OrReductionV src1 src2));
  effect(TEMP_DEF dst, TEMP vtmp);
  ins_cost(SVE_COST);
  format %{ "sve_reduce_orL $dst, $src1, $src2\t# orL reduction (sve)" %}
  ins_encode %{
    __ sve_orv(as_FloatRegister($vtmp$$reg), __ D, ptrue, as_FloatRegister($src2$$reg));
    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), __ D, 0);
    __ orr($dst$$Register, $dst$$Register, $src1$$Register);
  %}
  ins_pipe(pipe_slow);
%}

instruct reduce_orL_partial(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp,
                             pRegGov ptmp, rFlagsReg cr) %{
  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG &&
            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);
  match(Set dst (OrReductionV src1 src2));
  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);
  ins_cost(SVE_COST);
  format %{ "sve_reduce_orL $dst, $src1, $src2\t# orL reduction partial (sve)" %}
  ins_encode %{
    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), __ D, vector_length(this, $src2));
    __ sve_orv(as_FloatRegister($vtmp$$reg), __ D,
               as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));
    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), __ D, 0);
    __ orr($dst$$Register, $dst$$Register, $src1$$Register);
  %}
  ins_pipe(pipe_slow);
%}

// vector xor reduction

instruct reduce_eorI(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp) %{
  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG &&
            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);
  match(Set dst (XorReductionV src1 src2));
  effect(TEMP_DEF dst, TEMP vtmp);
  ins_cost(SVE_COST);
  format %{ "sve_reduce_eorI $dst, $src1, $src2\t# xorB/H/I reduction (sve) (may extend)" %}
  ins_encode %{
    BasicType bt = vector_element_basic_type(this, $src2);
    Assembler::SIMD_RegVariant variant = __ elemType_to_regVariant(bt);
    __ sve_eorv(as_FloatRegister($vtmp$$reg), variant, ptrue, as_FloatRegister($src2$$reg));
    __ smov($dst$$Register, as_FloatRegister($vtmp$$reg), variant, 0);
    __ eorw($dst$$Register, $dst$$Register, $src1$$Register);
    if (bt == T_BYTE) {
      __ sxtb($dst$$Register, $dst$$Register);
    } else if (bt == T_SHORT) {
      __ sxth($dst$$Register, $dst$$Register);
    } else {
      assert(bt == T_INT, "unsupported type");
    }
  %}
  ins_pipe(pipe_slow);
%}

instruct reduce_eorI_partial(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp,
                             pRegGov ptmp, rFlagsReg cr) %{
  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG &&
            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);
  match(Set dst (XorReductionV src1 src2));
  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);
  ins_cost(SVE_COST);
  format %{ "sve_reduce_eorI $dst, $src1, $src2\t# xorI reduction partial (sve) (may extend)" %}
  ins_encode %{
    BasicType bt = vector_element_basic_type(this, $src2);
    Assembler::SIMD_RegVariant variant = __ elemType_to_regVariant(bt);
    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), variant, vector_length(this, $src2));
    __ sve_eorv(as_FloatRegister($vtmp$$reg), variant,
                as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));
    __ smov($dst$$Register, as_FloatRegister($vtmp$$reg), variant, 0);
    __ eorw($dst$$Register, $dst$$Register, $src1$$Register);
    if (bt == T_BYTE) {
      __ sxtb($dst$$Register, $dst$$Register);
    } else if (bt == T_SHORT) {
      __ sxth($dst$$Register, $dst$$Register);
    } else {
      assert(bt == T_INT, "unsupported type");
    }
  %}
  ins_pipe(pipe_slow);
%}

instruct reduce_eorL(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp) %{
  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG &&
            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);
  match(Set dst (XorReductionV src1 src2));
  effect(TEMP_DEF dst, TEMP vtmp);
  ins_cost(SVE_COST);
  format %{ "sve_reduce_eorL $dst, $src1, $src2\t# xorL reduction (sve)" %}
  ins_encode %{
    __ sve_eorv(as_FloatRegister($vtmp$$reg), __ D, ptrue, as_FloatRegister($src2$$reg));
    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), __ D, 0);
    __ eor($dst$$Register, $dst$$Register, $src1$$Register);
  %}
  ins_pipe(pipe_slow);
%}

instruct reduce_eorL_partial(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp,
                             pRegGov ptmp, rFlagsReg cr) %{
  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG &&
            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);
  match(Set dst (XorReductionV src1 src2));
  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);
  ins_cost(SVE_COST);
  format %{ "sve_reduce_eorL $dst, $src1, $src2\t# xorL reduction partial (sve)" %}
  ins_encode %{
    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), __ D, vector_length(this, $src2));
    __ sve_eorv(as_FloatRegister($vtmp$$reg), __ D,
                as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));
    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), __ D, 0);
    __ eor($dst$$Register, $dst$$Register, $src1$$Register);
  %}
  ins_pipe(pipe_slow);
%}

dnl
dnl REDUCE_MAXMIN_I($1,      $2,      $3 )
dnl REDUCE_MAXMIN_I(min_max, op_mame, cmp)
define(`REDUCE_MAXMIN_I', `
instruct reduce_$1I(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp) %{
  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize &&
            (n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_BYTE ||
             n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_SHORT ||
             n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_INT));
  match(Set dst ($2 src1 src2));
  effect(TEMP_DEF dst, TEMP vtmp);
  ins_cost(SVE_COST);
  format %{ "sve_reduce_$1I $dst, $src1, $src2\t# reduce $1B/S/I (sve)" %}
  ins_encode %{
    BasicType bt = vector_element_basic_type(this, $src2);
    Assembler::SIMD_RegVariant variant = __ elemType_to_regVariant(bt);
    __ sve_s$1v(as_FloatRegister($vtmp$$reg), variant, ptrue, as_FloatRegister($src2$$reg));
    __ smov($dst$$Register, as_FloatRegister($vtmp$$reg), variant, 0);
    __ cmpw($dst$$Register, $src1$$Register);
    __ cselw(as_Register($dst$$reg), as_Register($dst$$reg), as_Register($src1$$reg), Assembler::$3);
  %}
  ins_pipe(pipe_slow);
%}')dnl
dnl
dnl REDUCE_MAXMIN_L($1,      $2,      $3 )
dnl REDUCE_MAXMIN_L(min_max, op_name, cmp)
define(`REDUCE_MAXMIN_L', `
instruct reduce_$1L(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp) %{
  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize &&
            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG);
  match(Set dst ($2 src1 src2));
  effect(TEMP_DEF dst, TEMP vtmp);
  ins_cost(SVE_COST);
  format %{ "sve_reduce_$1L $dst, $src1, $src2\t# reduce $1L partial (sve)" %}
  ins_encode %{
    __ sve_s$1v(as_FloatRegister($vtmp$$reg), __ D, ptrue, as_FloatRegister($src2$$reg));
    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), __ D, 0);
    __ cmp($dst$$Register, $src1$$Register);
    __ csel(as_Register($dst$$reg), as_Register($dst$$reg), as_Register($src1$$reg), Assembler::$3);
  %}
  ins_pipe(pipe_slow);
%}')dnl
dnl
dnl REDUCE_MAXMIN_I_PARTIAL($1,      $2,      $3 )
dnl REDUCE_MAXMIN_I_PARTIAL(min_max, op_mame, cmp)
define(`REDUCE_MAXMIN_I_PARTIAL', `
instruct reduce_$1I_partial(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp,
                             pRegGov ptmp, rFlagsReg cr) %{
  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize &&
            (n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_BYTE ||
             n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_SHORT ||
             n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_INT));
  match(Set dst ($2 src1 src2));
  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);
  ins_cost(SVE_COST);
  format %{ "sve_reduce_$1I $dst, $src1, $src2\t# reduce $1I partial (sve)" %}
  ins_encode %{
    BasicType bt = vector_element_basic_type(this, $src2);
    Assembler::SIMD_RegVariant variant = __ elemType_to_regVariant(bt);
    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), variant, vector_length(this, $src2));
    __ sve_s$1v(as_FloatRegister($vtmp$$reg), variant,
                 as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));
    __ smov($dst$$Register, as_FloatRegister($vtmp$$reg), variant, 0);
    __ cmpw($dst$$Register, $src1$$Register);
    __ cselw(as_Register($dst$$reg), as_Register($dst$$reg), as_Register($src1$$reg), Assembler::$3);
  %}
  ins_pipe(pipe_slow);
%}')dnl
dnl
dnl REDUCE_MAXMIN_L_PARTIAL($1,      $2,      $3 )
dnl REDUCE_MAXMIN_L_PARTIAL(min_max, op_name, cmp)
define(`REDUCE_MAXMIN_L_PARTIAL', `
instruct reduce_$1L_partial(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp,
                             pRegGov ptmp, rFlagsReg cr) %{
  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize &&
            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG);
  match(Set dst ($2 src1 src2));
  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);
  ins_cost(SVE_COST);
  format %{ "sve_reduce_$1L $dst, $src1, $src2\t# reduce $1L partial (sve)" %}
  ins_encode %{
    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), __ D, vector_length(this, $src2));
    __ sve_s$1v(as_FloatRegister($vtmp$$reg), __ D,
                 as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));
    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), __ D, 0);
    __ cmp($dst$$Register, $src1$$Register);
    __ csel(as_Register($dst$$reg), as_Register($dst$$reg), as_Register($src1$$reg), Assembler::$3);
  %}
  ins_pipe(pipe_slow);
%}')dnl
dnl
dnl REDUCE_FMINMAX($1,      $2,          $3,           $4,   $5         )
dnl REDUCE_FMINMAX(min_max, name_suffix, element_type, size, reg_src_dst)
define(`REDUCE_FMINMAX', `
instruct reduce_$1$2($5 dst, $5 src1, vReg src2) %{
  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == $3 &&
            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);
  match(Set dst (translit($1, `m', `M')ReductionV src1 src2));
  ins_cost(INSN_COST);
  effect(TEMP_DEF dst);
  format %{ "sve_f$1v $dst, $src2 # vector (sve) ($4)\n\t"
            "f$1s $dst, $dst, $src1\t# $1 reduction $2" %}
  ins_encode %{
    __ sve_f$1v(as_FloatRegister($dst$$reg), __ $4,
         ptrue, as_FloatRegister($src2$$reg));
    __ f`$1'translit($4, `SD', `sd')(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));
  %}
  ins_pipe(pipe_slow);
%}')dnl
dnl
dnl
dnl REDUCE_FMINMAX_PARTIAL($1,      $2,          $3,           $4,   $5         )
dnl REDUCE_FMINMAX_PARTIAL(min_max, name_suffix, element_type, size, reg_src_dst)
define(`REDUCE_FMINMAX_PARTIAL', `
instruct reduce_$1$2_partial($5 dst, $5 src1, vReg src2,
                             pRegGov ptmp, rFlagsReg cr) %{
  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == $3 &&
            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);
  match(Set dst (translit($1, `m', `M')ReductionV src1 src2));
  ins_cost(INSN_COST);
  effect(TEMP_DEF dst, TEMP ptmp, KILL cr);
  format %{ "sve_reduce_$1$2 $dst, $src1, $src2\t# reduce $1 $4 partial (sve)" %}
  ins_encode %{
    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), __ $4, vector_length(this, $src2));
    __ sve_f$1v(as_FloatRegister($dst$$reg), __ $4,
         as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));
    __ f`$1'translit($4, `SD', `sd')(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));
  %}
  ins_pipe(pipe_slow);
%}')dnl

// vector max reduction
REDUCE_MAXMIN_I(max, MaxReductionV, GT)
REDUCE_MAXMIN_I_PARTIAL(max, MaxReductionV, GT)
REDUCE_MAXMIN_L(max, MaxReductionV, GT)
REDUCE_MAXMIN_L_PARTIAL(max, MaxReductionV, GT)
REDUCE_FMINMAX(max, F, T_FLOAT,  S, vRegF)
REDUCE_FMINMAX_PARTIAL(max, F, T_FLOAT,  S, vRegF)
REDUCE_FMINMAX(max, D, T_DOUBLE, D, vRegD)
REDUCE_FMINMAX_PARTIAL(max, D, T_DOUBLE, D, vRegD)

// vector min reduction
REDUCE_MAXMIN_I(min, MinReductionV, LT)
REDUCE_MAXMIN_I_PARTIAL(min, MinReductionV, LT)
REDUCE_MAXMIN_L(min, MinReductionV, LT)
REDUCE_MAXMIN_L_PARTIAL(min, MinReductionV, LT)
REDUCE_FMINMAX(min, F, T_FLOAT,  S, vRegF)
REDUCE_FMINMAX_PARTIAL(min, F, T_FLOAT,  S, vRegF)
REDUCE_FMINMAX(min, D, T_DOUBLE, D, vRegD)
REDUCE_FMINMAX_PARTIAL(min, D, T_DOUBLE, D, vRegD)

// vector Math.rint, floor, ceil

instruct vroundD(vReg dst, vReg src, immI rmode) %{
  predicate(UseSVE > 0 &&
            n->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE);
  match(Set dst (RoundDoubleModeV src rmode));
  format %{ "sve_frint $dst, $src, $rmode\t# vector (sve) (D)" %}
  ins_encode %{
    switch ($rmode$$constant) {
      case RoundDoubleModeNode::rmode_rint:
        __ sve_frintn(as_FloatRegister($dst$$reg), __ D,
             ptrue, as_FloatRegister($src$$reg));
        break;
      case RoundDoubleModeNode::rmode_floor:
        __ sve_frintm(as_FloatRegister($dst$$reg), __ D,
             ptrue, as_FloatRegister($src$$reg));
        break;
      case RoundDoubleModeNode::rmode_ceil:
        __ sve_frintp(as_FloatRegister($dst$$reg), __ D,
             ptrue, as_FloatRegister($src$$reg));
        break;
    }
  %}
  ins_pipe(pipe_slow);
%}
dnl
dnl REPLICATE($1,        $2,      $3,      $4,   $5         )
dnl REPLICATE(insn_name, op_name, reg_src, size, min_vec_len)
define(`REPLICATE', `
instruct $1(vReg dst, $3 src) %{
  predicate(UseSVE > 0);
  match(Set dst ($2 src));
  ins_cost(SVE_COST);
  format %{ "sve_dup  $dst, $src\t# vector (sve) ($4)" %}
  ins_encode %{
    __ sve_dup(as_FloatRegister($dst$$reg), __ $4, as_Register($src$$reg));
  %}
  ins_pipe(pipe_slow);
%}')dnl
dnl
dnl REPLICATE_IMM8($1,        $2,      $3,       $4,   $5         )
dnl REPLICATE_IMM8(insn_name, op_name, imm_type, size, min_vec_len)
define(`REPLICATE_IMM8', `
instruct $1(vReg dst, $3 con) %{
  predicate(UseSVE > 0);
  match(Set dst ($2 con));
  ins_cost(SVE_COST);
  format %{ "sve_dup  $dst, $con\t# vector (sve) ($4)" %}
  ins_encode %{
    __ sve_dup(as_FloatRegister($dst$$reg), __ $4, $con$$constant);
  %}
  ins_pipe(pipe_slow);
%}')dnl
dnl
dnl FREPLICATE($1,        $2,      $3,        $4)
dnl FREPLICATE(insn_name, op_name, reg_src, size)
define(`FREPLICATE', `
instruct $1(vReg dst, $3 src) %{
  predicate(UseSVE > 0);
  match(Set dst ($2 src));
  ins_cost(SVE_COST);
  format %{ "sve_cpy  $dst, $src\t# vector (sve) ($4)" %}
  ins_encode %{
    __ sve_cpy(as_FloatRegister($dst$$reg), __ $4,
         ptrue, as_FloatRegister($src$$reg));
  %}
  ins_pipe(pipe_slow);
%}')dnl

// vector replicate
REPLICATE(replicateB, ReplicateB, iRegIorL2I, B, 16)
REPLICATE(replicateS, ReplicateS, iRegIorL2I, H, 8)
REPLICATE(replicateI, ReplicateI, iRegIorL2I, S, 4)
REPLICATE(replicateL, ReplicateL, iRegL,      D, 2)
REPLICATE_IMM8(replicateB_imm8, ReplicateB, immI8,        B, 16)
REPLICATE_IMM8(replicateS_imm8, ReplicateS, immI8_shift8, H, 8)
REPLICATE_IMM8(replicateI_imm8, ReplicateI, immI8_shift8, S, 4)
REPLICATE_IMM8(replicateL_imm8, ReplicateL, immL8_shift8, D, 2)
FREPLICATE(replicateF, ReplicateF, vRegF, S, 4)
FREPLICATE(replicateD, ReplicateD, vRegD, D, 2)
dnl
dnl VSHIFT_TRUE_PREDICATE($1,        $2,      $3,   $4,          $5  )
dnl VSHIFT_TRUE_PREDICATE(insn_name, op_name, size, min_vec_len, insn)
define(`VSHIFT_TRUE_PREDICATE', `
instruct $1(vReg dst, vReg shift) %{
  predicate(UseSVE > 0);
  match(Set dst ($2 dst shift));
  ins_cost(SVE_COST);
  format %{ "$5 $dst, $dst, $shift\t# vector (sve) ($3)" %}
  ins_encode %{
    __ $5(as_FloatRegister($dst$$reg), __ $3,
         ptrue, as_FloatRegister($shift$$reg));
  %}
  ins_pipe(pipe_slow);
%}')dnl
dnl
dnl VSHIFT_IMM_UNPREDICATED($1,        $2,      $3,       $4,   $5,          $6  )
dnl VSHIFT_IMM_UNPREDICATED(insn_name, op_name, op_name2, size, min_vec_len, insn)
define(`VSHIFT_IMM_UNPREDICATED', `
instruct $1(vReg dst, vReg src, immI shift) %{
  predicate(UseSVE > 0);
  match(Set dst ($2 src ($3 shift)));
  ins_cost(SVE_COST);
  format %{ "$6 $dst, $src, $shift\t# vector (sve) ($4)" %}
  ins_encode %{
    int con = (int)$shift$$constant;dnl
ifelse(eval(index(`$1', `vasr') == 0 || index(`$1', `vlsr') == 0), 1, `
    if (con == 0) {
      __ sve_orr(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),
           as_FloatRegister($src$$reg));
      return;
    }')dnl
ifelse(eval(index(`$1', `vasr') == 0), 1, `ifelse(eval(index(`$4', `B') == 0), 1, `
    if (con >= 8) con = 7;')ifelse(eval(index(`$4', `H') == 0), 1, `
    if (con >= 16) con = 15;')')dnl
ifelse(eval(index(`$1', `vlsl') == 0  || index(`$1', `vlsr') == 0), 1, `ifelse(eval(index(`$4', `B') == 0), 1, `
    if (con >= 8) {
      __ sve_eor(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),
           as_FloatRegister($src$$reg));
      return;
    }')ifelse(eval(index(`$4', `H') == 0), 1, `
    if (con >= 16) {
      __ sve_eor(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),
           as_FloatRegister($src$$reg));
      return;
    }')')
    __ $6(as_FloatRegister($dst$$reg), __ $4,
         as_FloatRegister($src$$reg), con);
  %}
  ins_pipe(pipe_slow);
%}')dnl
dnl
dnl VSHIFT_COUNT($1,        $2,   $3,          $4  )
dnl VSHIFT_COUNT(insn_name, size, min_vec_len, type)
define(`VSHIFT_COUNT', `
instruct $1(vReg dst, iRegIorL2I cnt) %{
  predicate(UseSVE > 0 &&
            ELEMENT_SHORT_CHAR($4, n));
  match(Set dst (LShiftCntV cnt));
  match(Set dst (RShiftCntV cnt));
  format %{ "sve_dup $dst, $cnt\t# vector shift count (sve) ($2)" %}
  ins_encode %{
    __ sve_dup(as_FloatRegister($dst$$reg), __ $2, as_Register($cnt$$reg));
  %}
  ins_pipe(pipe_slow);
%}')dnl

// vector shift
VSHIFT_TRUE_PREDICATE(vasrB, RShiftVB,  B, 16, sve_asr)
VSHIFT_TRUE_PREDICATE(vasrS, RShiftVS,  H,  8, sve_asr)
VSHIFT_TRUE_PREDICATE(vasrI, RShiftVI,  S,  4, sve_asr)
VSHIFT_TRUE_PREDICATE(vasrL, RShiftVL,  D,  2, sve_asr)
VSHIFT_TRUE_PREDICATE(vlslB, LShiftVB,  B, 16, sve_lsl)
VSHIFT_TRUE_PREDICATE(vlslS, LShiftVS,  H,  8, sve_lsl)
VSHIFT_TRUE_PREDICATE(vlslI, LShiftVI,  S,  4, sve_lsl)
VSHIFT_TRUE_PREDICATE(vlslL, LShiftVL,  D,  2, sve_lsl)
VSHIFT_TRUE_PREDICATE(vlsrB, URShiftVB, B, 16, sve_lsr)
VSHIFT_TRUE_PREDICATE(vlsrS, URShiftVS, H,  8, sve_lsr)
VSHIFT_TRUE_PREDICATE(vlsrI, URShiftVI, S,  4, sve_lsr)
VSHIFT_TRUE_PREDICATE(vlsrL, URShiftVL, D,  2, sve_lsr)
VSHIFT_IMM_UNPREDICATED(vasrB_imm, RShiftVB,  RShiftCntV, B, 16, sve_asr)
VSHIFT_IMM_UNPREDICATED(vasrS_imm, RShiftVS,  RShiftCntV, H,  8, sve_asr)
VSHIFT_IMM_UNPREDICATED(vasrI_imm, RShiftVI,  RShiftCntV, S,  4, sve_asr)
VSHIFT_IMM_UNPREDICATED(vasrL_imm, RShiftVL,  RShiftCntV, D,  2, sve_asr)
VSHIFT_IMM_UNPREDICATED(vlsrB_imm, URShiftVB, RShiftCntV, B, 16, sve_lsr)
VSHIFT_IMM_UNPREDICATED(vlsrS_imm, URShiftVS, RShiftCntV, H,  8, sve_lsr)
VSHIFT_IMM_UNPREDICATED(vlsrI_imm, URShiftVI, RShiftCntV, S,  4, sve_lsr)
VSHIFT_IMM_UNPREDICATED(vlsrL_imm, URShiftVL, RShiftCntV, D,  2, sve_lsr)
VSHIFT_IMM_UNPREDICATED(vlslB_imm, LShiftVB,  LShiftCntV, B, 16, sve_lsl)
VSHIFT_IMM_UNPREDICATED(vlslS_imm, LShiftVS,  LShiftCntV, H,  8, sve_lsl)
VSHIFT_IMM_UNPREDICATED(vlslI_imm, LShiftVI,  LShiftCntV, S,  4, sve_lsl)
VSHIFT_IMM_UNPREDICATED(vlslL_imm, LShiftVL,  LShiftCntV, D,  2, sve_lsl)
VSHIFT_COUNT(vshiftcntB, B, 16, T_BYTE)
VSHIFT_COUNT(vshiftcntS, H,  8, T_SHORT)
VSHIFT_COUNT(vshiftcntI, S,  4, T_INT)
VSHIFT_COUNT(vshiftcntL, D,  2, T_LONG)

// vector sqrt
UNARY_OP_TRUE_PREDICATE(vsqrtF, SqrtVF, S, 16, sve_fsqrt)
UNARY_OP_TRUE_PREDICATE(vsqrtD, SqrtVD, D, 16, sve_fsqrt)

// vector sub
BINARY_OP_UNPREDICATED(vsubB, SubVB, B, 16, sve_sub)
BINARY_OP_UNPREDICATED(vsubS, SubVS, H, 8, sve_sub)
BINARY_OP_UNPREDICATED(vsubI, SubVI, S, 4, sve_sub)
BINARY_OP_UNPREDICATED(vsubL, SubVL, D, 2, sve_sub)
BINARY_OP_UNPREDICATED(vsubF, SubVF, S, 4, sve_fsub)
BINARY_OP_UNPREDICATED(vsubD, SubVD, D, 2, sve_fsub)

// vector mask cast

instruct vmaskcast(vReg dst) %{
  predicate(UseSVE > 0 && n->bottom_type()->is_vect()->length() == n->in(1)->bottom_type()->is_vect()->length() &&
            n->bottom_type()->is_vect()->length_in_bytes() == n->in(1)->bottom_type()->is_vect()->length_in_bytes());
  match(Set dst (VectorMaskCast dst));
  ins_cost(0);
  format %{ "vmaskcast $dst\t# empty (sve)" %}
  ins_encode %{
    // empty
  %}
  ins_pipe(pipe_class_empty);
%}

// ------------------------------ Vector cast -------------------------------
dnl
dnl
define(`VECTOR_CAST_EXTEND1', `
instruct vcvt$1to$2`'(vReg dst, vReg src)
%{
  predicate(UseSVE > 0 &&
            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($2));
  match(Set dst (VectorCast$1`'2X src));
  ins_cost(SVE_COST);
  format %{ "sve_$3  $dst, $4, $src\t# convert $1 to $2 vector" %}
  ins_encode %{
    __ sve_$3(as_FloatRegister($dst$$reg), __ $4, as_FloatRegister($src$$reg));
  %}
  ins_pipe(pipe_slow);
%}')dnl
dnl
dnl
define(`VECTOR_CAST_EXTEND2', `
instruct vcvt$1to$2`'(vReg dst, vReg src)
%{
  predicate(UseSVE > 0 &&
            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($2));
  match(Set dst (VectorCast$1`'2X src));
  ins_cost(2 * SVE_COST);
  format %{ "sve_$3  $dst, $4, $src\n\t"
            "sve_$3  $dst, $5, $dst\t# convert $1 to $2 vector" %}
  ins_encode %{
    __ sve_$3(as_FloatRegister($dst$$reg), __ $4, as_FloatRegister($src$$reg));
    __ sve_$3(as_FloatRegister($dst$$reg), __ $5, as_FloatRegister($dst$$reg));
  %}
  ins_pipe(pipe_slow);
%}')dnl
dnl
dnl
define(`VECTOR_CAST_EXTEND3', `
instruct vcvt$1to$2`'(vReg dst, vReg src)
%{
  predicate(UseSVE > 0 &&
            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($2));
  match(Set dst (VectorCast$1`'2X src));
  ins_cost(3 * SVE_COST);
  format %{ "sve_$3  $dst, $4, $src\n\t"
            "sve_$3  $dst, $5, $dst\n\t"
            "sve_$3  $dst, $6, $dst\t# convert $1 to $2 vector" %}
  ins_encode %{
    __ sve_$3(as_FloatRegister($dst$$reg), __ $4, as_FloatRegister($src$$reg));
    __ sve_$3(as_FloatRegister($dst$$reg), __ $5, as_FloatRegister($dst$$reg));
    __ sve_$3(as_FloatRegister($dst$$reg), __ $6, as_FloatRegister($dst$$reg));
  %}
  ins_pipe(pipe_slow);
%}')dnl
dnl
dnl
define(`VECTOR_CAST_NARROW1', `
instruct vcvt$1to$2`'(vReg dst, vReg src, vReg tmp)
%{
  predicate(UseSVE > 0 &&
            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($2));
  match(Set dst (VectorCast$1`'2X src));
  effect(TEMP tmp);
  ins_cost(2 * SVE_COST);
  format %{ "sve_$3  $tmp, $4, 0\n\t"
            "sve_$5  $dst, $4, $src, tmp\t# convert $1 to $2 vector" %}
  ins_encode %{
    __ sve_$3(as_FloatRegister($tmp$$reg), __ $4, 0);
    __ sve_$5(as_FloatRegister($dst$$reg), __ $4, as_FloatRegister($src$$reg), as_FloatRegister($tmp$$reg));
  %}
  ins_pipe(pipe_slow);
%}')dnl
dnl
dnl
define(`VECTOR_CAST_NARROW2', `
instruct vcvt$1to$2`'(vReg dst, vReg src, vReg tmp)
%{
  predicate(UseSVE > 0 &&
            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($2));
  match(Set dst (VectorCast$1`'2X src));
  effect(TEMP_DEF dst, TEMP tmp);
  ins_cost(3 * SVE_COST);
  format %{ "sve_$3  $tmp, $4, 0\n\t"
            "sve_$5  $dst, $4, $src, tmp\n\t"
            "sve_$5  $dst, $6, $dst, tmp\n\t# convert $1 to $2 vector" %}
  ins_encode %{
    __ sve_$3(as_FloatRegister($tmp$$reg), __ $4, 0);
    __ sve_$5(as_FloatRegister($dst$$reg), __ $4, as_FloatRegister($src$$reg), as_FloatRegister($tmp$$reg));
    __ sve_$5(as_FloatRegister($dst$$reg), __ $6, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
  %}
  ins_pipe(pipe_slow);
%}')dnl
dnl
dnl
define(`VECTOR_CAST_NARROW3', `
instruct vcvt$1to$2`'(vReg dst, vReg src, vReg tmp)
%{
  predicate(UseSVE > 0 &&
            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($2));
  match(Set dst (VectorCast$1`'2X src));
  effect(TEMP_DEF dst, TEMP tmp);
  ins_cost(4 * SVE_COST);
  format %{ "sve_$3  $tmp, $4, 0\n\t"
            "sve_$5  $dst, $4, $src, tmp\n\t"
            "sve_$5  $dst, $6, $dst, tmp\n\t"
            "sve_$5  $dst, $7, $dst, tmp\n\t# convert $1 to $2 vector" %}
  ins_encode %{
    __ sve_$3(as_FloatRegister($tmp$$reg), __ $4, 0);
    __ sve_$5(as_FloatRegister($dst$$reg), __ $4, as_FloatRegister($src$$reg), as_FloatRegister($tmp$$reg));
    __ sve_$5(as_FloatRegister($dst$$reg), __ $6, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
    __ sve_$5(as_FloatRegister($dst$$reg), __ $7, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
  %}
  ins_pipe(pipe_slow);
%}')dnl
dnl
dnl
define(`VECTOR_CAST_I2F_EXTEND2', `
instruct vcvt$1to$2`'(vReg dst, vReg src)
%{
  predicate(UseSVE > 0 &&
            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($2));
  match(Set dst (VectorCast$1`'2X src));
  ins_cost(3 * SVE_COST);
  format %{ "sve_$3  $dst, $4, $src\n\t"
            "sve_$3  $dst, $5, $dst\n\t"
            "sve_$6  $dst, $5, $dst, $5\t# convert $1 to $2 vector" %}
  ins_encode %{
    __ sve_$3(as_FloatRegister($dst$$reg), __ $4, as_FloatRegister($src$$reg));
    __ sve_$3(as_FloatRegister($dst$$reg), __ $5, as_FloatRegister($dst$$reg));
    __ sve_$6(as_FloatRegister($dst$$reg), __ $5, ptrue, as_FloatRegister($dst$$reg), __ $5);
  %}
  ins_pipe(pipe_slow);
%}')dnl
dnl
dnl
define(`VECTOR_CAST_I2F_EXTEND3', `
instruct vcvt$1to$2`'(vReg dst, vReg src)
%{
  predicate(UseSVE > 0 &&
            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($2));
  match(Set dst (VectorCast$1`'2X src));
  ins_cost(4 * SVE_COST);
  format %{ "sve_$3  $dst, $4, $src\n\t"
            "sve_$3  $dst, $5, $dst\n\t"
            "sve_$3  $dst, $6, $dst\n\t"
            "sve_$7  $dst, $6, $dst, $6\t# convert $1 to $2 vector" %}
  ins_encode %{
    __ sve_$3(as_FloatRegister($dst$$reg), __ $4, as_FloatRegister($src$$reg));
    __ sve_$3(as_FloatRegister($dst$$reg), __ $5, as_FloatRegister($dst$$reg));
    __ sve_$3(as_FloatRegister($dst$$reg), __ $6, as_FloatRegister($dst$$reg));
    __ sve_$7(as_FloatRegister($dst$$reg), __ $6, ptrue, as_FloatRegister($dst$$reg), __ $6);
  %}
  ins_pipe(pipe_slow);
%}')dnl
dnl
dnl
define(`VECTOR_CAST_X2F_NARROW1', `
instruct vcvt$1to$2`'(vReg dst, vReg src, vReg tmp)
%{
  predicate(UseSVE > 0 &&
            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($2));
  match(Set dst (VectorCast$1`'2X src));
  effect(TEMP_DEF dst, TEMP tmp);
  ins_cost(3 * SVE_COST);
  format %{ "sve_$3  $dst, $4, $src, $5\n\t"
            "sve_$6  $tmp, $7, 0\n\t"
            "sve_$8  $dst, $7, $dst, $tmp\t# convert $1 to $2 vector" %}
  ins_encode %{
    __ sve_$3(as_FloatRegister($dst$$reg), __ $4, ptrue, as_FloatRegister($src$$reg), __ $5);
    __ sve_$6(as_FloatRegister($tmp$$reg), __ $7, 0);
    __ sve_$8(as_FloatRegister($dst$$reg), __ $7, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
  %}
  ins_pipe(pipe_slow);
%}')dnl
dnl
dnl
define(`VECTOR_CAST_X2X', `
instruct vcvt$1to$2`'(vReg dst, vReg src)
%{
  predicate(UseSVE > 0 &&
            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($2));
  match(Set dst (VectorCast$1`'2X src));
  ins_cost(SVE_COST);
  format %{ "sve_$3  $dst, $4, $src, $4\t# convert $1 to $2 vector" %}
  ins_encode %{
    __ sve_$3(as_FloatRegister($dst$$reg), __ $4, ptrue, as_FloatRegister($src$$reg), __ $4);
  %}
  ins_pipe(pipe_slow);
%}')dnl
dnl
dnl
define(`VECTOR_CAST_X2F_EXTEND1', `
instruct vcvt$1to$2`'(vReg dst, vReg src)
%{
  predicate(UseSVE > 0 &&
            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($2));
  match(Set dst (VectorCast$1`'2X src));
  ins_cost(2 * SVE_COST);
  format %{ "sve_$3  $dst, $4, $src\n\t"
            "sve_$5  $dst, $4, $dst, $6\t# convert $1 to $2 vector" %}
  ins_encode %{
    __ sve_$3(as_FloatRegister($dst$$reg), __ $4, as_FloatRegister($src$$reg));
    __ sve_$5(as_FloatRegister($dst$$reg), __ $4, ptrue, as_FloatRegister($dst$$reg), __ $6);
  %}
  ins_pipe(pipe_slow);
%}')dnl
dnl
dnl
define(`VECTOR_CAST_F2X_NARROW1', `
instruct vcvt$1to$2`'(vReg dst, vReg src, vReg tmp)
%{
  predicate(UseSVE > 0 &&
            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($2));
  match(Set dst (VectorCast$1`'2X src));
  effect(TEMP_DEF dst, TEMP tmp);
  ins_cost(3 * SVE_COST);
  format %{ "sve_$3  $dst, $4, $src, $4\n\t"
            "sve_$5  $tmp, $6, 0\n\t"
            "sve_$7  $dst, $6, $dst, tmp\t# convert $1 to $2 vector" %}
  ins_encode %{
    __ sve_$3(as_FloatRegister($dst$$reg), __ $4, ptrue, as_FloatRegister($src$$reg), __ $4);
    __ sve_$5(as_FloatRegister($tmp$$reg), __ $6, 0);
    __ sve_$7(as_FloatRegister($dst$$reg), __ $6, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
  %}
  ins_pipe(pipe_slow);
%}')dnl
dnl
dnl
define(`VECTOR_CAST_F2X_NARROW2', `
instruct vcvt$1to$2`'(vReg dst, vReg src, vReg tmp)
%{
  predicate(UseSVE > 0 &&
            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($2));
  match(Set dst (VectorCast$1`'2X src));
  effect(TEMP_DEF dst, TEMP tmp);
  ins_cost(4 * SVE_COST);
  format %{ "sve_$3  $dst, $4, $src, $4\n\t"
            "sve_$5  $tmp, $6, 0\n\t"
            "sve_$7  $dst, $6, $dst, tmp\n\t"
            "sve_$7  $dst, $8, $dst, tmp\n\t# convert $1 to $2 vector" %}
  ins_encode %{
    __ sve_$3(as_FloatRegister($dst$$reg), __ $4, ptrue, as_FloatRegister($src$$reg), __ $4);
    __ sve_$5(as_FloatRegister($tmp$$reg), __ $6, 0);
    __ sve_$7(as_FloatRegister($dst$$reg), __ $6, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
    __ sve_$7(as_FloatRegister($dst$$reg), __ $8, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
  %}
  ins_pipe(pipe_slow);
%}')dnl
dnl
dnl
define(`VECTOR_CAST_F2X_EXTEND1', `
instruct vcvt$1to$2`'(vReg dst, vReg src)
%{
  predicate(UseSVE > 0 &&
            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($2));
  match(Set dst (VectorCast$1`'2X src));
  ins_cost(2 * SVE_COST);
  format %{ "sve_$3  $dst, $4, $src, $4\n\t"
            "sve_$5  $dst, $6, $dst\t# convert $1 to $2 vector" %}
  ins_encode %{
    __ sve_$3(as_FloatRegister($dst$$reg), __ $4, ptrue, as_FloatRegister($src$$reg), __ $4);
    __ sve_$5(as_FloatRegister($dst$$reg), __ $6, as_FloatRegister($dst$$reg));
  %}
  ins_pipe(pipe_slow);
%}')dnl
dnl
dnl
define(`VECTOR_CAST_F2X_NARROW3', `
instruct vcvt$1to$2`'(vReg dst, vReg src, vReg tmp)
%{
  predicate(UseSVE > 0 &&
            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($2));
  match(Set dst (VectorCast$1`'2X src));
  effect(TEMP_DEF dst, TEMP tmp);
  ins_cost(5 * SVE_COST);
  format %{ "sve_$3  $dst, $4, $src, $4\n\t"
            "sve_$5  $tmp, $6, 0\n\t"
            "sve_$7  $dst, $6, $dst, tmp\n\t"
            "sve_$7  $dst, $8, $dst, tmp\n\t"
            "sve_$7  $dst, $9, $dst, tmp\n\t# convert $1 to $2 vector" %}
  ins_encode %{
    __ sve_$3(as_FloatRegister($dst$$reg), __ $4, ptrue, as_FloatRegister($src$$reg), __ $4);
    __ sve_$5(as_FloatRegister($tmp$$reg), __ $6, 0);
    __ sve_$7(as_FloatRegister($dst$$reg), __ $6, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
    __ sve_$7(as_FloatRegister($dst$$reg), __ $8, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
    __ sve_$7(as_FloatRegister($dst$$reg), __ $9, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
  %}
  ins_pipe(pipe_slow);
%}')dnl
dnl
VECTOR_CAST_EXTEND1(B, S, sunpklo, H)
VECTOR_CAST_EXTEND2(B, I, sunpklo, H, S)
VECTOR_CAST_EXTEND3(B, L, sunpklo, H, S, D)
VECTOR_CAST_I2F_EXTEND2(B, F, sunpklo, H, S, scvtf)
VECTOR_CAST_I2F_EXTEND3(B, D, sunpklo, H, S, D, scvtf)
dnl
VECTOR_CAST_NARROW1(S, B, dup, B, uzp1)
VECTOR_CAST_EXTEND1(S, I, sunpklo, S)
VECTOR_CAST_EXTEND2(S, L, sunpklo, S, D)
VECTOR_CAST_X2F_EXTEND1(S, F, sunpklo, S, scvtf, S)
VECTOR_CAST_I2F_EXTEND2(S, D, sunpklo, S, D, scvtf)
dnl
VECTOR_CAST_NARROW2(I, B, dup, H, uzp1, B)
VECTOR_CAST_NARROW1(I, S, dup, H, uzp1)
VECTOR_CAST_EXTEND1(I, L, sunpklo, D)
VECTOR_CAST_X2X(I, F, scvtf, S)
VECTOR_CAST_X2F_EXTEND1(I, D, sunpklo, D, scvtf, D)
dnl
VECTOR_CAST_NARROW3(L, B, dup, S, uzp1, H, B)
VECTOR_CAST_NARROW2(L, S, dup, S, uzp1, H)
VECTOR_CAST_NARROW1(L, I, dup, S, uzp1)
VECTOR_CAST_X2F_NARROW1(L, F, scvtf, S, D, dup, S, uzp1)
VECTOR_CAST_X2X(L, D, scvtf, D)
dnl
VECTOR_CAST_F2X_NARROW2(F, B, fcvtzs, S, dup, H, uzp1, B)
VECTOR_CAST_F2X_NARROW1(F, S, fcvtzs, S, dup, H, uzp1)
VECTOR_CAST_X2X(F, I, fcvtzs, S)
VECTOR_CAST_F2X_EXTEND1(F, L, fcvtzs, S, sunpklo, D)
VECTOR_CAST_X2F_EXTEND1(F, D, sunpklo, D, fcvt, S)
dnl
VECTOR_CAST_F2X_NARROW3(D, B, fcvtzs, D, dup, S, uzp1, H, B)
VECTOR_CAST_F2X_NARROW2(D, S, fcvtzs, D, dup, S, uzp1, H)
VECTOR_CAST_F2X_NARROW1(D, I, fcvtzs, D, dup, S, uzp1)
VECTOR_CAST_X2X(D, L, fcvtzs, D)
VECTOR_CAST_X2F_NARROW1(D, F, fcvt, S, D, dup, S, uzp1)
dnl
dnl
// ------------------------------ Vector extract ---------------------------------
define(`VECTOR_EXTRACT_SXT', `
instruct extract$1`'($2 dst, vReg src, immI idx, pRegGov pTmp, rFlagsReg cr)
%{
  predicate(UseSVE > 0);
  match(Set dst (Extract$1 src idx));
  effect(TEMP pTmp, KILL cr);
  ins_cost(2 * SVE_COST);
  format %{ "sve_extract $dst, $3, $pTmp, $src, $idx\n\t"
            "sbfmw $dst, $dst, 0U, $5\t# extract from vector($1)" %}
  ins_encode %{
    __ sve_extract(as_$4($dst$$reg), __ $3, as_PRegister($pTmp$$reg),
                   as_FloatRegister($src$$reg), (int)($idx$$constant));
    __ sbfmw(as_$4($dst$$reg), as_$4($dst$$reg), 0U, $5);
  %}
  ins_pipe(pipe_slow);
%}')dnl
dnl                $1 $2         $3 $4        $5
VECTOR_EXTRACT_SXT(B, iRegINoSp, B, Register, 7U)
VECTOR_EXTRACT_SXT(S, iRegINoSp, H, Register, 15U)

dnl
define(`VECTOR_EXTRACT', `
instruct extract$1`'($2 dst, vReg src, immI idx, pRegGov pTmp, rFlagsReg cr)
%{
  predicate(UseSVE > 0);
  match(Set dst (Extract$1 src idx));
  effect(TEMP pTmp, KILL cr);
  ins_cost(2 * SVE_COST);
  format %{ "sve_extract $dst, $3, $pTmp, $src, $idx\t# extract from vector($1)" %}
  ins_encode %{
    __ sve_extract(as_$4($dst$$reg), __ $3, as_PRegister($pTmp$$reg),
                   as_FloatRegister($src$$reg), (int)($idx$$constant));
  %}
  ins_pipe(pipe_slow);
%}')dnl
dnl            $1 $2         $3 $4
VECTOR_EXTRACT(I, iRegINoSp, S, Register)
VECTOR_EXTRACT(L, iRegLNoSp, D, Register)
VECTOR_EXTRACT(F, vRegF,     S, FloatRegister)
VECTOR_EXTRACT(D, vRegD,     D, FloatRegister)

// ------------------------------- VectorTest ----------------------------------
dnl
dnl VTEST($1,      $2,   $3,  $4  )
dnl VTEST(op_name, pred, imm, cond)
define(`VTEST', `
instruct vtest_$1`'(iRegINoSp dst, vReg src1, vReg src2, pReg pTmp, rFlagsReg cr)
%{
  predicate(UseSVE > 0 && n->in(1)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize &&
            static_cast<const VectorTestNode*>(n)->get_predicate() == BoolTest::$2);
  match(Set dst (VectorTest src1 src2));
  effect(TEMP pTmp, KILL cr);
  ins_cost(SVE_COST);
  format %{ "sve_cmpeq $pTmp, $src1, $3\n\t"
            "csetw $dst, $4\t# VectorTest (sve) - $1" %}
  ins_encode %{
    // "src2" is not used for sve.
    BasicType bt = vector_element_basic_type(this, $src1);
    Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(bt);
    __ sve_cmpeq(as_PRegister($pTmp$$reg), size, ptrue,
                 as_FloatRegister($src1$$reg), $3);
    __ csetw(as_Register($dst$$reg), Assembler::$4);
  %}
  ins_pipe(pipe_slow);
%}')dnl
dnl
VTEST(alltrue, overflow, 0, EQ)
VTEST(anytrue, ne,      -1, NE)
dnl
dnl
dnl VTEST_PARTIAL($1,      $2,   $3,  $4  )
dnl VTEST_PARTIAL(op_name, pred, imm, cond)
define(`VTEST_PARTIAL', `
instruct vtest_$1_partial`'(iRegINoSp dst, vReg src1, vReg src2, pRegGov pTmp, rFlagsReg cr)
%{
  predicate(UseSVE > 0 && n->in(1)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize &&
            static_cast<const VectorTestNode*>(n)->get_predicate() == BoolTest::$2);
  match(Set dst (VectorTest src1 src2));
  effect(TEMP pTmp, KILL cr);
  ins_cost(SVE_COST);
  format %{ "vtest_$1_partial $dst, $src1, $src2\t# VectorTest partial (sve) - $1" %}
  ins_encode %{
    // "src2" is not used for sve.
    BasicType bt = vector_element_basic_type(this, $src1);
    Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(bt);
    __ sve_whilelo_zr_imm(as_PRegister($pTmp$$reg), size, vector_length(this, $src1));
    __ sve_cmpeq(as_PRegister($pTmp$$reg), size, as_PRegister($pTmp$$reg),
                 as_FloatRegister($src1$$reg), $3);
    __ csetw(as_Register($dst$$reg), Assembler::$4);
  %}
  ins_pipe(pipe_slow);
%}')dnl
dnl
VTEST_PARTIAL(alltrue, overflow, 0, EQ)
VTEST_PARTIAL(anytrue, ne,      -1, NE)

// ------------------------------ Vector insert ---------------------------------

instruct insertI_small(vReg dst, vReg src, iRegIorL2I val, immI idx, pRegGov pTmp, rFlagsReg cr)
%{
  predicate(UseSVE > 0 && n->as_Vector()->length() <= 32 &&
            (n->bottom_type()->is_vect()->element_basic_type() == T_BYTE ||
             n->bottom_type()->is_vect()->element_basic_type() == T_SHORT ||
             n->bottom_type()->is_vect()->element_basic_type() == T_INT));
  match(Set dst (VectorInsert (Binary src val) idx));
  effect(TEMP_DEF dst, TEMP pTmp, KILL cr);
  ins_cost(4 * SVE_COST);
  format %{ "sve_index $dst, -16, 1\t# (B/S/I)\n\t"
            "sve_cmpeq $pTmp, $dst, ($idx-#16) # shift from [0, 31] to [-16, 15]\n\t"
            "sve_orr $dst, $src, $src\n\t"
            "sve_cpy $dst, $pTmp, $val\t# insert into vector (B/S/I)" %}
  ins_encode %{
    BasicType bt = vector_element_basic_type(this, $src);
    Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(bt);
    __ sve_index(as_FloatRegister($dst$$reg), size, -16, 1);
    __ sve_cmpeq(as_PRegister($pTmp$$reg), size, ptrue,
                 as_FloatRegister($dst$$reg), (int)($idx$$constant) - 16);
    __ sve_orr(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg), as_FloatRegister($src$$reg));
    __ sve_cpy(as_FloatRegister($dst$$reg), size, as_PRegister($pTmp$$reg), as_Register($val$$reg));
  %}
  ins_pipe(pipe_slow);
%}

instruct insertF_small(vReg dst, vReg src, vRegF val, immI idx, pRegGov pTmp, rFlagsReg cr)
%{
  predicate(UseSVE > 0 && n->as_Vector()->length() <= 32 &&
            n->bottom_type()->is_vect()->element_basic_type() == T_FLOAT);
  match(Set dst (VectorInsert (Binary src val) idx));
  effect(TEMP_DEF dst, TEMP pTmp, KILL cr);
  ins_cost(4 * SVE_COST);
  format %{ "sve_index $dst, S, -16, 1\n\t"
            "sve_cmpeq $pTmp, $dst, ($idx-#16) # shift from [0, 31] to [-16, 15]\n\t"
            "sve_orr $dst, $src, $src\n\t"
            "sve_cpy $dst, $pTmp, $val\t# insert into vector (F)" %}
  ins_encode %{
    __ sve_index(as_FloatRegister($dst$$reg), __ S, -16, 1);
    __ sve_cmpeq(as_PRegister($pTmp$$reg), __ S, ptrue,
                 as_FloatRegister($dst$$reg), (int)($idx$$constant) - 16);
    __ sve_orr(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg), as_FloatRegister($src$$reg));
    __ sve_cpy(as_FloatRegister($dst$$reg), __ S, as_PRegister($pTmp$$reg), as_FloatRegister($val$$reg));
  %}
  ins_pipe(pipe_slow);
%}

instruct insertI(vReg dst, vReg src, iRegIorL2I val, immI idx, vReg tmp1, pRegGov pTmp, rFlagsReg cr)
%{
  predicate(UseSVE > 0 && n->as_Vector()->length() > 32 &&
            (n->bottom_type()->is_vect()->element_basic_type() == T_BYTE ||
             n->bottom_type()->is_vect()->element_basic_type() == T_SHORT ||
             n->bottom_type()->is_vect()->element_basic_type() == T_INT));
  match(Set dst (VectorInsert (Binary src val) idx));
  effect(TEMP_DEF dst, TEMP tmp1, TEMP pTmp, KILL cr);
  ins_cost(5 * SVE_COST);
  format %{ "sve_index $tmp1, 0, 1\t# (B/S/I)\n\t"
            "sve_dup $dst, $idx\t# (B/S/I)\n\t"
            "sve_cmpeq $pTmp, $tmp1, $dst\n\t"
            "sve_orr $dst, $src, $src\n\t"
            "sve_cpy $dst, $pTmp, $val\t# insert into vector (B/S/I)" %}
  ins_encode %{
    BasicType bt = vector_element_basic_type(this, $src);
    Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(bt);
    __ sve_index(as_FloatRegister($tmp1$$reg), size, 0, 1);
    __ sve_dup(as_FloatRegister($dst$$reg), size, (int)($idx$$constant));
    __ sve_cmpeq(as_PRegister($pTmp$$reg), size, ptrue,
                 as_FloatRegister($tmp1$$reg), as_FloatRegister($dst$$reg));
    __ sve_orr(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg), as_FloatRegister($src$$reg));
    __ sve_cpy(as_FloatRegister($dst$$reg), size, as_PRegister($pTmp$$reg), as_Register($val$$reg));
  %}
  ins_pipe(pipe_slow);
%}
dnl
dnl
define(`VECTOR_INSERT_D', `
instruct insert$1`'(vReg dst, vReg src, $2 val, immI idx, pRegGov pTmp, rFlagsReg cr)
%{
  predicate(UseSVE > 0 &&
            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($1));
  match(Set dst (VectorInsert (Binary src val) idx));
  effect(TEMP_DEF dst, TEMP pTmp, KILL cr);
  ins_cost(4 * SVE_COST);
  format %{ "sve_index $dst, $3, -16, 1\n\t"
            "sve_cmpeq $pTmp, $dst, ($idx-#16) # shift from [0, 31] to [-16, 15]\n\t"
            "sve_orr $dst, $src, $src\n\t"
            "sve_cpy $dst, $pTmp, $val\t# insert into vector ($1)" %}
  ins_encode %{
    __ sve_index(as_FloatRegister($dst$$reg), __ $3, -16, 1);
    __ sve_cmpeq(as_PRegister($pTmp$$reg), __ $3, ptrue,
                 as_FloatRegister($dst$$reg), (int)($idx$$constant) - 16);
    __ sve_orr(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg), as_FloatRegister($src$$reg));
    __ sve_cpy(as_FloatRegister($dst$$reg), __ $3, as_PRegister($pTmp$$reg), as_$4($val$$reg));
  %}
  ins_pipe(pipe_slow);
%}')dnl
dnl             $1 $2     $3 $4
VECTOR_INSERT_D(L, iRegL, D, Register)
VECTOR_INSERT_D(D, vRegD, D, FloatRegister)

instruct insertF(vReg dst, vReg src, vRegF val, immI idx, vReg tmp1, pRegGov pTmp, rFlagsReg cr)
%{
  predicate(UseSVE > 0 && n->as_Vector()->length() > 32 &&
            n->bottom_type()->is_vect()->element_basic_type() == T_FLOAT);
  match(Set dst (VectorInsert (Binary src val) idx));
  effect(TEMP_DEF dst, TEMP tmp1, TEMP pTmp, KILL cr);
  ins_cost(5 * SVE_COST);
  format %{ "sve_index $tmp1, S, 0, 1\n\t"
            "sve_dup $dst, S, $idx\n\t"
            "sve_cmpeq $pTmp, $tmp1, $dst\n\t"
            "sve_orr $dst, $src, $src\n\t"
            "sve_cpy $dst, $pTmp, $val\t# insert into vector (F)" %}
  ins_encode %{
    __ sve_index(as_FloatRegister($tmp1$$reg), __ S, 0, 1);
    __ sve_dup(as_FloatRegister($dst$$reg), __ S, (int)($idx$$constant));
    __ sve_cmpeq(as_PRegister($pTmp$$reg), __ S, ptrue,
                 as_FloatRegister($tmp1$$reg), as_FloatRegister($dst$$reg));
    __ sve_orr(as_FloatRegister($dst$$reg),
               as_FloatRegister($src$$reg),
               as_FloatRegister($src$$reg));
    __ sve_cpy(as_FloatRegister($dst$$reg), __ S,
               as_PRegister($pTmp$$reg), as_FloatRegister($val$$reg));
  %}
  ins_pipe(pipe_slow);
%}

// ------------------------------ Vector shuffle -------------------------------

instruct loadshuffleB(vReg dst, vReg src)
%{
  predicate(UseSVE > 0 && n->bottom_type()->is_vect()->element_basic_type() == T_BYTE);
  match(Set dst (VectorLoadShuffle src));
  ins_cost(SVE_COST);
  format %{ "sve_orr $dst, $src, $src\t# vector load shuffle (B)" %}
  ins_encode %{
    if (as_FloatRegister($dst$$reg) != as_FloatRegister($src$$reg)) {
      __ sve_orr(as_FloatRegister($dst$$reg),
                 as_FloatRegister($src$$reg),
                 as_FloatRegister($src$$reg));
    }
  %}
  ins_pipe(pipe_slow);
%}

instruct loadshuffleS(vReg dst, vReg src)
%{
  predicate(UseSVE > 0 && n->bottom_type()->is_vect()->element_basic_type() == T_SHORT);
  match(Set dst (VectorLoadShuffle src));
  ins_cost(SVE_COST);
  format %{ "sve_uunpklo $dst, $src\t# vector load shuffle (B to H)" %}
  ins_encode %{
    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($src$$reg));
  %}
  ins_pipe(pipe_slow);
%}

instruct loadshuffleI(vReg dst, vReg src)
%{
  predicate(UseSVE > 0 &&
           (n->bottom_type()->is_vect()->element_basic_type() == T_INT ||
            n->bottom_type()->is_vect()->element_basic_type() == T_FLOAT));
  match(Set dst (VectorLoadShuffle src));
  ins_cost(2 * SVE_COST);
  format %{ "sve_uunpklo $dst, H, $src\n\t"
            "sve_uunpklo $dst, S, $dst\t# vector load shuffle (B to S)" %}
  ins_encode %{
    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($src$$reg));
    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($dst$$reg));
  %}
  ins_pipe(pipe_slow);
%}

instruct loadshuffleL(vReg dst, vReg src)
%{
  predicate(UseSVE > 0 &&
           (n->bottom_type()->is_vect()->element_basic_type() == T_LONG ||
            n->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE));
  match(Set dst (VectorLoadShuffle src));
  ins_cost(3 * SVE_COST);
  format %{ "sve_uunpklo $dst, H, $src\n\t"
            "sve_uunpklo $dst, S, $dst\n\t"
            "sve_uunpklo $dst, D, $dst\t# vector load shuffle (B to D)" %}
  ins_encode %{
    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($src$$reg));
    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($dst$$reg));
    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ D, as_FloatRegister($dst$$reg));
  %}
  ins_pipe(pipe_slow);
%}

// ------------------------------ Vector rearrange -------------------------------

instruct rearrange(vReg dst, vReg src, vReg shuffle)
%{
  predicate(UseSVE > 0);
  match(Set dst (VectorRearrange src shuffle));
  ins_cost(SVE_COST);
  format %{ "sve_tbl $dst, $src, $shuffle\t# vector rearrange" %}
  ins_encode %{
    BasicType bt = vector_element_basic_type(this, $src);
    Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(bt);
    __ sve_tbl(as_FloatRegister($dst$$reg), size,
               as_FloatRegister($src$$reg), as_FloatRegister($shuffle$$reg));
  %}
  ins_pipe(pipe_slow);
%}

// ------------------------------ Vector Load Gather ---------------------------------

instruct gatherI(vReg dst, indirect mem, vReg idx) %{
  predicate(UseSVE > 0 &&
            n->as_LoadVectorGather()->memory_size() == MaxVectorSize &&
            (n->bottom_type()->is_vect()->element_basic_type() == T_INT ||
             n->bottom_type()->is_vect()->element_basic_type() == T_FLOAT));
  match(Set dst (LoadVectorGather mem idx));
  ins_cost(SVE_COST);
  format %{ "load_vector_gather $dst, $mem, $idx\t# vector load gather (I/F)" %}
  ins_encode %{
    __ sve_ld1w_gather(as_FloatRegister($dst$$reg), ptrue, as_Register($mem$$base), as_FloatRegister($idx$$reg));
  %}
  ins_pipe(pipe_slow);
%}

instruct gatherL(vReg dst, indirect mem, vReg idx) %{
  predicate(UseSVE > 0 &&
            n->as_LoadVectorGather()->memory_size() == MaxVectorSize &&
            (n->bottom_type()->is_vect()->element_basic_type() == T_LONG ||
             n->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE));
  match(Set dst (LoadVectorGather mem idx));
  ins_cost(2 * SVE_COST);
  format %{ "sve_uunpklo $idx, $idx\n\t"
            "load_vector_gather $dst, $mem, $idx\t# vector load gather (L/D)" %}
  ins_encode %{
    __ sve_uunpklo(as_FloatRegister($idx$$reg), __ D, as_FloatRegister($idx$$reg));
    __ sve_ld1d_gather(as_FloatRegister($dst$$reg), ptrue, as_Register($mem$$base), as_FloatRegister($idx$$reg));
  %}
  ins_pipe(pipe_slow);
%}

// ------------------------------ Vector Load Gather Partial-------------------------------

instruct gatherI_partial(vReg dst, indirect mem, vReg idx, pRegGov pTmp, rFlagsReg cr) %{
  predicate(UseSVE > 0 &&
            n->as_LoadVectorGather()->memory_size() < MaxVectorSize &&
            (n->bottom_type()->is_vect()->element_basic_type() == T_INT ||
             n->bottom_type()->is_vect()->element_basic_type() == T_FLOAT));
  match(Set dst (LoadVectorGather mem idx));
  effect(TEMP pTmp, KILL cr);
  ins_cost(2 * SVE_COST + INSN_COST);
  format %{ "sve_whilelo_zr_imm $pTmp, vector_length\n\t"
            "load_vector_gather $dst, $pTmp, $mem, $idx\t# vector load gather partial (I/F)" %}
  ins_encode %{
    __ sve_whilelo_zr_imm(as_PRegister($pTmp$$reg), __ S, vector_length(this));
    __ sve_ld1w_gather(as_FloatRegister($dst$$reg), as_PRegister($pTmp$$reg), as_Register($mem$$base), as_FloatRegister($idx$$reg));
  %}
  ins_pipe(pipe_slow);
%}

instruct gatherL_partial(vReg dst, indirect mem, vReg idx, pRegGov pTmp, rFlagsReg cr) %{
  predicate(UseSVE > 0 &&
            n->as_LoadVectorGather()->memory_size() < MaxVectorSize &&
            (n->bottom_type()->is_vect()->element_basic_type() == T_LONG ||
             n->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE));
  match(Set dst (LoadVectorGather mem idx));
  effect(TEMP pTmp, KILL cr);
  ins_cost(3 * SVE_COST + INSN_COST);
  format %{ "sve_whilelo_zr_imm $pTmp, vector_length\n\t"
            "sve_uunpklo $idx, $idx\n\t"
            "load_vector_gather $dst, $pTmp, $mem, $idx\t# vector load gather partial (L/D)" %}
  ins_encode %{
    __ sve_whilelo_zr_imm(as_PRegister($pTmp$$reg), __ D, vector_length(this));
    __ sve_uunpklo(as_FloatRegister($idx$$reg), __ D, as_FloatRegister($idx$$reg));
    __ sve_ld1d_gather(as_FloatRegister($dst$$reg), as_PRegister($pTmp$$reg), as_Register($mem$$base), as_FloatRegister($idx$$reg));
  %}
  ins_pipe(pipe_slow);
%}

// ------------------------------ Vector Store Scatter -------------------------------

instruct scatterI(indirect mem, vReg src, vReg idx) %{
  predicate(UseSVE > 0 &&
            n->as_StoreVectorScatter()->memory_size() == MaxVectorSize &&
            (n->in(3)->in(1)->bottom_type()->is_vect()->element_basic_type() == T_INT ||
             n->in(3)->in(1)->bottom_type()->is_vect()->element_basic_type() == T_FLOAT));
  match(Set mem (StoreVectorScatter mem (Binary src idx)));
  ins_cost(SVE_COST);
  format %{ "store_vector_scatter $mem, $idx, $src\t# vector store scatter (I/F)" %}
  ins_encode %{
    __ sve_st1w_scatter(as_FloatRegister($src$$reg), ptrue, as_Register($mem$$base), as_FloatRegister($idx$$reg));
  %}
  ins_pipe(pipe_slow);
%}

instruct scatterL(indirect mem, vReg src, vReg idx) %{
  predicate(UseSVE > 0 &&
            n->as_StoreVectorScatter()->memory_size() == MaxVectorSize &&
            (n->in(3)->in(1)->bottom_type()->is_vect()->element_basic_type() == T_LONG ||
             n->in(3)->in(1)->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE));
  match(Set mem (StoreVectorScatter mem (Binary src idx)));
  ins_cost(2 * SVE_COST);
  format %{ "sve_uunpklo $idx, $idx\n\t"
            "store_vector_scatter $mem, $idx, $src\t# vector store scatter (L/D)" %}
  ins_encode %{
    __ sve_uunpklo(as_FloatRegister($idx$$reg), __ D, as_FloatRegister($idx$$reg));
    __ sve_st1d_scatter(as_FloatRegister($src$$reg), ptrue, as_Register($mem$$base), as_FloatRegister($idx$$reg));
  %}
  ins_pipe(pipe_slow);
%}

// ------------------------------ Vector Store Scatter Partial-------------------------------

instruct scatterI_partial(indirect mem, vReg src, vReg idx, pRegGov pTmp, rFlagsReg cr) %{
  predicate(UseSVE > 0 &&
            n->as_StoreVectorScatter()->memory_size() < MaxVectorSize &&
            (n->in(3)->in(1)->bottom_type()->is_vect()->element_basic_type() == T_INT ||
             n->in(3)->in(1)->bottom_type()->is_vect()->element_basic_type() == T_FLOAT));
  match(Set mem (StoreVectorScatter mem (Binary src idx)));
  effect(TEMP pTmp, KILL cr);
  ins_cost(2 * SVE_COST + INSN_COST);
  format %{ "sve_whilelo_zr_imm $pTmp, vector_length\n\t"
            "store_vector_scatter $mem, $pTmp, $idx, $src\t# vector store scatter partial (I/F)" %}
  ins_encode %{
    __ sve_whilelo_zr_imm(as_PRegister($pTmp$$reg), __ S, vector_length(this, $src));
    __ sve_st1w_scatter(as_FloatRegister($src$$reg), as_PRegister($pTmp$$reg), as_Register($mem$$base), as_FloatRegister($idx$$reg));
  %}
  ins_pipe(pipe_slow);
%}

instruct scatterL_partial(indirect mem, vReg src, vReg idx, pRegGov pTmp, rFlagsReg cr) %{
  predicate(UseSVE > 0 &&
            n->as_StoreVectorScatter()->memory_size() < MaxVectorSize &&
            (n->in(3)->in(1)->bottom_type()->is_vect()->element_basic_type() == T_LONG ||
             n->in(3)->in(1)->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE));
  match(Set mem (StoreVectorScatter mem (Binary src idx)));
  effect(TEMP pTmp, KILL cr);
  ins_cost(3 * SVE_COST + INSN_COST);
  format %{ "sve_whilelo_zr_imm $pTmp, vector_length\n\t"
            "sve_uunpklo $idx, $idx\n\t"
            "store_vector_scatter $mem, $pTmp, $idx, $src\t# vector store scatter partial (L/D)" %}
  ins_encode %{
    __ sve_whilelo_zr_imm(as_PRegister($pTmp$$reg), __ D, vector_length(this, $src));
    __ sve_uunpklo(as_FloatRegister($idx$$reg), __ D, as_FloatRegister($idx$$reg));
    __ sve_st1d_scatter(as_FloatRegister($src$$reg), as_PRegister($pTmp$$reg), as_Register($mem$$base), as_FloatRegister($idx$$reg));
  %}
  ins_pipe(pipe_slow);
%}


// ------------------------------ Vector Load Const -------------------------------

instruct loadconB(vReg dst, immI0 src) %{
  predicate(UseSVE > 0 &&
            n->bottom_type()->is_vect()->element_basic_type() == T_BYTE);
  match(Set dst (VectorLoadConst src));
  ins_cost(SVE_COST);
  format %{ "sve_index $dst, 0, 1\t# generate iota indices" %}
  ins_encode %{
    __ sve_index(as_FloatRegister($dst$$reg), __ B, 0, 1);
  %}
  ins_pipe(pipe_slow);
%}

// Intrisics for String.indexOf(char)

dnl
define(`STRING_INDEXOF_CHAR', `
instruct string$1_indexof_char_sve(iRegP_R1 str1, iRegI_R2 cnt1, iRegI_R3 ch,
                                  iRegI_R0 result, vReg ztmp1, vReg ztmp2,
                                  pRegGov pgtmp, pReg ptmp, rFlagsReg cr)
%{
  match(Set result (StrIndexOfChar (Binary str1 cnt1) ch));
  predicate((UseSVE > 0) && (((StrIndexOfCharNode*)n)->encoding() == StrIntrinsicNode::$1));
  effect(TEMP ztmp1, TEMP ztmp2, TEMP pgtmp, TEMP ptmp, KILL cr);

  format %{ "String$2 IndexOf char[] $str1,$cnt1,$ch -> $result # use sve" %}

  ins_encode %{
    __ string_indexof_char_sve($str1$$Register, $cnt1$$Register, $ch$$Register, $result$$Register,
                               as_FloatRegister($ztmp1$$reg), as_FloatRegister($ztmp2$$reg),
                               as_PRegister($pgtmp$$reg), as_PRegister($ptmp$$reg), $3 /* isL */);
  %}
  ins_pipe(pipe_class_memory);
%}')dnl
dnl                 $1 $2      $3
STRING_INDEXOF_CHAR(L, Latin1, true)
STRING_INDEXOF_CHAR(U, UTF16,  false)

dnl
dnl VMASK_REDUCTION($1,     $2,      $3  )
dnl VMASK_REDUCTION(suffix, op_name, cost)
define(`VMASK_REDUCTION', `
instruct vmask_$1(iRegINoSp dst, vReg src, pReg ptmp, rFlagsReg cr) %{
  predicate(UseSVE > 0 &&
            n->in(1)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);
  match(Set dst ($2 src));
  effect(TEMP ptmp, KILL cr);
  ins_cost($3 * SVE_COST);
  format %{ "vmask_$1 $dst, $src\t# vector mask $1 (sve)" %}
  ins_encode %{
    __ sve_vmask_reduction(this->ideal_Opcode(), $dst$$Register, __ B,
                           as_FloatRegister($src$$reg), ptrue, as_PRegister($ptmp$$reg));
  %}
  ins_pipe(pipe_slow);
%}')dnl
dnl
// ---------------------------- Vector mask reductions ---------------------------
VMASK_REDUCTION(truecount, VectorMaskTrueCount, 2)
VMASK_REDUCTION(firsttrue, VectorMaskFirstTrue, 3)
VMASK_REDUCTION(lasttrue,  VectorMaskLastTrue, 4)
dnl
dnl VMASK_REDUCTION_PARTIAL($1,     $2,      $3  )
dnl VMASK_REDUCTION_PARTIAL(suffix, op_name, cost)
define(`VMASK_REDUCTION_PARTIAL', `
instruct vmask_$1_partial(iRegINoSp dst, vReg src, pRegGov ifelse($1, `firsttrue', `pgtmp, pReg ptmp', `ptmp'), rFlagsReg cr) %{
  predicate(UseSVE > 0 &&
            n->in(1)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);
  match(Set dst ($2 src));
  effect(TEMP ifelse($1, `firsttrue', `pgtmp, TEMP ptmp', `ptmp'), KILL cr);
  ins_cost($3 * SVE_COST);
  format %{ "vmask_$1 $dst, $src\t# vector mask $1 partial (sve)" %}
  ins_encode %{
    __ sve_whilelo_zr_imm(as_PRegister(ifelse($1, `firsttrue', `$pgtmp', `$ptmp')$$reg), __ B, vector_length(this, $src));
    __ sve_vmask_reduction(this->ideal_Opcode(), $dst$$Register, __ B, as_FloatRegister($src$$reg),
                           as_PRegister(ifelse($1, `firsttrue', `$pgtmp', `$ptmp')$$reg), as_PRegister($ptmp$$reg));
  %}
  ins_pipe(pipe_slow);
%}')dnl
dnl
VMASK_REDUCTION_PARTIAL(truecount, VectorMaskTrueCount, 3)
VMASK_REDUCTION_PARTIAL(firsttrue, VectorMaskFirstTrue, 4)
VMASK_REDUCTION_PARTIAL(lasttrue,  VectorMaskLastTrue, 5)

dnl
dnl VSTOREMASK_REDUCTION($1,     $2,      $3  )
dnl VSTOREMASK_REDUCTION(suffix, op_name, cost)
define(`VSTOREMASK_REDUCTION', `
instruct vstoremask_$1(iRegINoSp dst, vReg src, immI esize, pReg ptmp, rFlagsReg cr) %{
  predicate(UseSVE > 0 &&
            n->in(1)->in(1)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);
  match(Set dst ($2 (VectorStoreMask src esize)));
  effect(TEMP ptmp, KILL cr);
  ins_cost($3 * SVE_COST);
  format %{ "vstoremask_$1 $dst, $src\t# vector mask $1 (sve)" %}
  ins_encode %{
    int size = $esize$$constant;
    assert(size == 1 || size == 2 || size == 4 || size == 8, "unsupported element size");
    Assembler::SIMD_RegVariant variant = __ elemBytes_to_regVariant(size);
    __ sve_vmask_reduction(this->ideal_Opcode(), $dst$$Register, variant, as_FloatRegister($src$$reg),
                           ptrue, as_PRegister($ptmp$$reg), vector_length(this, $src));
  %}
  ins_pipe(pipe_slow);
%}')dnl
dnl
// ----------------- Vector mask reductions combined with VectorMaskStore ---------------
VSTOREMASK_REDUCTION(truecount, VectorMaskTrueCount, 2)
VSTOREMASK_REDUCTION(firsttrue, VectorMaskFirstTrue, 3)
VSTOREMASK_REDUCTION(lasttrue,  VectorMaskLastTrue, 4)
dnl
dnl VSTOREMASK_REDUCTION_PARTIAL($1,     $2,      $3  )
dnl VSTOREMASK_REDUCTION_PARTIAL(suffix, op_name, cost)
define(`VSTOREMASK_REDUCTION_PARTIAL', `
instruct vstoremask_$1_partial(iRegINoSp dst, vReg src, immI esize, pRegGov ifelse($1, `firsttrue', `pgtmp, pReg ptmp', `ptmp'), rFlagsReg cr) %{
  predicate(UseSVE > 0 &&
            n->in(1)->in(1)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);
  match(Set dst ($2 (VectorStoreMask src esize)));
  effect(TEMP ifelse($1, `firsttrue', `pgtmp, TEMP ptmp', `ptmp'), KILL cr);
  ins_cost($3 * SVE_COST);
  format %{ "vstoremask_$1 $dst, $src\t# vector mask $1 partial (sve)" %}
  ins_encode %{
    int size = $esize$$constant;
    assert(size == 1 || size == 2 || size == 4 || size == 8, "unsupported element size");
    Assembler::SIMD_RegVariant variant = __ elemBytes_to_regVariant(size);
    __ sve_whilelo_zr_imm(as_PRegister(ifelse($1, `firsttrue', `$pgtmp', `$ptmp')$$reg), variant, vector_length(this, $src));
    __ sve_vmask_reduction(this->ideal_Opcode(), $dst$$Register, variant, as_FloatRegister($src$$reg),
                           as_PRegister(ifelse($1, `firsttrue', `$pgtmp', `$ptmp')$$reg), as_PRegister($ptmp$$reg), MaxVectorSize / size);
  %}
  ins_pipe(pipe_slow);
%}')dnl
dnl
VSTOREMASK_REDUCTION_PARTIAL(truecount, VectorMaskTrueCount, 3)
VSTOREMASK_REDUCTION_PARTIAL(firsttrue, VectorMaskFirstTrue, 4)
VSTOREMASK_REDUCTION_PARTIAL(lasttrue,  VectorMaskLastTrue, 5)
